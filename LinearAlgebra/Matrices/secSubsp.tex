%!TEX root = ../larxxia.tex

\section{Subspaces, basis, and dimension}
\label{sec:sbd}
\secttoc

\begin{comment}
\pooliv{\S3.5, p191--206} \layiv{\S4.1--3} \holti{\S4.1--3}
\end{comment}


\begin{quoted}{\index{Galileo Galilei}Galileo Galilei, 1610}
%Philosophy is written in this grand book---I mean the universe---which stands continually open to our gaze, but the book cannot be understood unless one first learns to comprehend the language and read the letters in which it is composed.  
%It is written in the language of mathematics.  
%Its characters are triangles, circles, and other geometrical figures without which it is humanly impossible to understand a single word of it; without these, one is wandering about in a dark labyrinth.
[Nature] is written in that great book which ever lies before our eyes---I mean the universe---but we cannot understand it if we do not first learn the language and grasp the symbols in which it is written. 
The book is written in the mathematical language, and the symbols are triangles, circles, and other geometric figures, without whose help it is impossible to comprehend a single word of it; without which one wanders in vain through a dark labyrinth.
%(as quoted by Kline, 1972, pp. 328--329. See also Machamer 1998a, pp. 64--65 for a slightly different translation.)
\end{quoted}


Some of the most fundamental geometric structures in mathematics, especially linear algebra, are the lines or planes through the origin, and higher dimensional analogues.
For example, a general solution of linear equations often involves linear combinations such as \((-2,1,0,0)s+(-\frac{15}7,0,\frac97,1)t\) (\cref{eg:homosysiv}) and \(y_3\vv_3+y_4\vv_4\) (\cref{eg:3x4findc}): such combinations for all values of the free variables form a plane through the origin (\cref{sec:nvep}).
The aim of this section is to connect geometric structures, such as lines and planes, to the information in a \idx{singular value decomposition}.
The structures are called \idx{subspace}s.


\subsection{Subspaces are lines, planes, and so on}

\index{subspace|(}
Let's introduce graphically the concept of a ``subspace''.
\cref{def:subspace} then gives the precise algebraic description.

\begin{example} \label{eg:viewsubs}
The following graphs illustrate the concept of subspaces through examples (imagine the graphs extend to infinity, as appropriate).
\begin{enumerate}[ref=\ref{eg:viewsubs}(\alph*)]
\newcommand{\PB}[1]{\quad\parbox[b]{11em}{\raggedright #1}}
\item\label[example]{eg:viewsubsa} \begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize
    ,axis equal image, axis lines=middle] 
    \addplot[blue,thick] {x/2};
\end{axis}
\end{tikzpicture}
\PB{is a subspace as it is a straight line through the origin.}

\item \begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize
    ,axis equal image, axis lines=middle ] 
    \addplot[blue,thick] {1-0.4*x};
\end{axis}
\end{tikzpicture}
\PB{is \emph{not} a subspace as it does not include the origin.}

\item\label[example]{eg:viewsubsc} \begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize
    ,axis equal image, axis lines=middle ] 
    \addplot[blue,thick] {x-x^2/20};
\end{axis}
\end{tikzpicture}
\PB{is \emph{not} a subspace as it curves.}

\item \begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize,ymin=-2.2,ymax=2.2
    ,axis equal, axis lines=middle ] 
    \addplot[blue,smooth,samples=30,domain=0:360,thick] ({2*cos(x)},{2*sin(3*x)});
\end{axis}
\end{tikzpicture}
\PB{is \emph{not} a subspace as it not only curves, but also does not include the origin.}

\begin{OmitV1}
\item \begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize
    ,axis equal image, axis lines=middle ] 
    \addplot[blue,thick] {-1.5*x};
\end{axis}
\end{tikzpicture}
\PB{is a subspace.}
\end{OmitV1}

\item\label[example]{eg:viewsubsf} \begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize,xmin=-4,ymin=-2
    ,axis equal image, axis lines=middle ] 
    \addplot[blue,thick,domain=0:5] {x/2};
    \addplot[only marks,blue] coordinates {(0,0)};
\end{axis}
\end{tikzpicture}
\PB{where the disc indicates an end to the line, is \emph{not} a subspace as it does not extend infinitely in both directions.}

\item \begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize
    ,axis equal image    ] 
    \addplot3[blue,samples y=0,thick] ({x},{x},{x/2});
    \addplot3[only marks,black] coordinates {(0,0,0)};
\end{axis}
\end{tikzpicture}
\PB{is a subspace as it is a line through the origin (marked~$\bullet$ in these 3D plots).}

\item\label[example]{eg:viewsubsh} \begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize
    ,axis equal image    ] 
    \addplot3[surf,samples=9,opacity=0.5] {-x/6+y/3};
    \addplot3[only marks,black] coordinates {(0,0,0)};
\end{axis}
\end{tikzpicture}
\PB{is a subspace as it is a plane through the origin.}

\item\label[example]{eg:viewsubsi} \begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize
    ,axis equal image    ] 
    \addplot3[only marks,black] coordinates {(0,0,0)};
    \addplot3[surf,samples=9,opacity=0.5] {5+x/6+y/3};
\end{axis}
\end{tikzpicture}
\PB{is \emph{not} a subspace as it does not go through the origin.}

\item \begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize
    ,axis equal image, width=13em    ] 
    \addplot3[only marks,black] coordinates {(0,0,0)};
    \addplot3[surf,opacity=0.5] {x^2/10-y^2/20};
\end{axis}
\end{tikzpicture}
\PB{is \emph{not} a subspace as it curves.}

\end{enumerate}
\end{example}



\begin{activity}
Given the examples and comments of \cref{eg:viewsubs},
which of the following is a subspace?
\actposs{\begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize
    ,axis equal image, axis lines=middle ] 
    \addplot[blue,thick] {x/2};
\end{axis} \end{tikzpicture}}
{\begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize
    ,axis equal image, axis lines=middle ] 
    \addplot[blue,only marks,samples=11] {-x};
\end{axis} \end{tikzpicture}}
{\begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize
    ,axis equal image, axis lines=middle ] 
    \addplot[blue,thick] {x^2/6};
\end{axis} \end{tikzpicture}}
{\begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize
    ,axis equal image, axis lines=middle ] 
    \addplot[blue,thick] {1-x/3};
\end{axis} \end{tikzpicture}}
\end{activity}




The following definition expresses precisely in algebra the concept of a subspace.
This book uses the `blackboard bold' font, such as \WW\ and~\RR, for names of spaces and subspaces.

% I think we need to use \in by now
Recall that the mathematical symbol~``\bfidx{$\in$}''\index{in, $\in$|textbf} means~``in'' or ``in the \idx{set}'' or ``is an element of the set''.
For two examples: ``\(c\in\RR\)\index{R@\RR}'' means ``\(c\)~is a real number''; whereas ``\(\vv\in\RR^3\)'' means ``\(\vv\)~is a vector with three components''.
For conciseness, hereafter this book uses~``\(\in\)'' extensively.


\begin{definition} \label{def:subspace} 
A \bfidx{subspace}~\WW\ of~\(\RR^n\) is a set of vectors with \(\ov\in\WW\), and such that for every \(c\in\RR\) and for every \(\uv,\vv\in\WW\), then both \(\uv+\vv\in\WW\) and \(c\uv\in\WW\). 
(When these properties hold we often say that~\WW\ is \bfidx{closed} under addition and \idx{scalar multiplication}.) 
\end{definition}


\begin{example} \label{eg:somsubs}
Use \cref{def:subspace} to determine whether each of the following are subspaces, or not. 
\begin{enumerate}[ref=\ref{eg:somsubs}(\alph*)]
\item 
All vectors~\((x,y)\) in the line \(y=x/2\) (\cref{eg:viewsubsa}).

\needlines5
\begin{solution} \ \\
\begin{figbox}{\begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize
    ,xlabel={$x$},ylabel={$y$}
    ,axis equal image, axis lines=middle] 
    \addplot[blue,thick] {x/2};
\end{axis}
\end{tikzpicture}}%
The origin, the zero vector~\ov, is in the line \(y=x/2\) as \(x=y=0\) satisfies the equation.
The line \(y=x/2\) is composed of vectors in the form \(\uv=(1,\frac12)t\) for some parameter~\(t\).
Then for any \(c\in\RR\)\,, \(c\uv=c(1,\frac12)t=(1,\frac12)(ct)=(1,\frac12)t'\) for new parameter \(t'=ct\)\,; hence \(c\uv\)~is in the line.
Let \(\vv=(1,\frac12)s\) be another vector in the line for some parameter~\(s\), then \(\uv+\vv=(1,\frac12)t+(1,\frac12)s=(1,\frac12)(t+s)=(1,\frac12)t'\) for new parameter \(t'=t+s\)\,; hence \(\uv+\vv\) is in the line.
The three requirements of \cref{def:subspace} are met, and so this line is \text{a subspace.}
\aqed

\end{figbox}
\end{solution}

\item All vectors \((x,y)\) with end-points on the curve \(y=x-x^2/20\) (\cref{eg:viewsubsc}).

\needlines5
\begin{solution} \ \\
\begin{figbox}{\begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize,domain=-5:25
    ,xlabel={$x$},ylabel={$y$}
    ,axis equal image, axis lines=middle ] 
    \addplot[blue,thick] {x-x^2/20};
    \addplot[red,thick,quiver={u=20,v=0},-stealth] coordinates {(0,0)};
\end{axis}
\end{tikzpicture}}%
A vector is `in the set' when its end-point lies on a plot of the set, as to the right.
To show something is not a subspace, we only need to give one instance when any one of the properties fail.
One instance is that the vector \((20,0)\) is in the curve as \(20-20^2/20=0\)\,, but the scalar multiple of half of this vector \(\frac12(20,0)=(10,0)\) is not as \(10-10^2/20=5\neq0\)\,.
That is, the curve is not closed under scalar multiplication and hence is not \text{a subspace.}
\aqed

\end{figbox}
\end{solution}

\item All vectors \((x,y)\) in the line \(y=x/2\) for \(x,y\geq0\) (\cref{eg:viewsubsf}).

\needlines6
\begin{solution} \ \\
\begin{figbox}{\begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize,xmin=-4,ymin=-2
    ,xlabel={$x$},ylabel={$y$}
    ,axis equal image, axis lines=middle ] 
    \addplot[blue,thick,domain=0:5] {x/2};
    \addplot[only marks,blue] coordinates {(0,0)};
    \addplot[red,thick,quiver={u=2,v=1},-stealth] coordinates {(0,0)};
    \addplot[brown,thick,quiver={u=-2,v=-1},-stealth] coordinates {(0,0)};
\end{axis}
\end{tikzpicture}}%
A vector is `in the set' when its end-point lies on a plot of the set, as to the right.
Although vectors \((x,y)\) in the line \(y=x/2\) for \(x,y\geq0\) includes the origin and is closed under addition, it fails the scalar multiplication test.
For example, \(\uv=(2,1)\) is in the line, but the scalar multiple \((-1)\uv=(-2,-1)\) is not.
Hence it is not \text{a subspace.}
\aqed

\end{figbox}
\end{solution}


\item All vectors \((x,y,z)\) in the plane \(z=-x/6+y/3\) (\cref{eg:viewsubsh}).

\needlines8
\begin{solution} \ \\
\begin{figbox}{\qview{30}{34}{\begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize
    ,axis equal image ,view={\q}{30}   ] 
    \addplot3[surf,samples=9,opacity=0.5] {-x/6+y/3};
    \addplot3[only marks,black] coordinates {(0,0,0)};
\end{axis}
\end{tikzpicture}}}%
The origin, the zero vector~\ov, is in the plane \(z=-x/6+y/3\) as \(x=y=z=0\) satisfies the equation.
A vector \(\uv=(u_1,u_2,u_3)\) is in the plane provided \(-u_1+2u_2-6u_3=0\)\,.
Consider \(c\uv=(cu_1,cu_2,cu_3)\) for which \(-(cu_1)+2(cu_2)-6(cu_3) =c(-u_1+2u_2-6u_3) =c\times0=0\) and hence must also be in the plane.
Also let vector \(\vv=(v_1,v_2,v_3)\) be in the plane and consider \(\uv+\vv=(u_1+v_1,u_2+v_2,u_3+v_3)\) for which \(-(u_1+v_1)+2(u_2+v_2)-6(u_3+v_3) =-u_1-v_1+2u_2+2v_2-6u_3-6v_3 =(-u_1+2u_2-6u_3) +(-v_1+2v_2-6v_3) =0+0 =0\) and hence must also be in the plane.
The three requirements of \cref{def:subspace} are met, and so this plane is \text{a subspace.}
\end{figbox}
\end{solution}


\item All vectors \((x,y,z)\) in the plane \(z=5+x/6+y/3\) (\cref{eg:viewsubsi}).
\begin{solution} 
The origin is not in the plane as \(\uv=(0,0,0)\) does not satisfy the equation.  Hence this plane is not a subspace.
\end{solution}


\item\label[example]{eg:somsubsf} \(\{\ov\}\) (the set of the zero vector in some~\(\RR^n\)).
\begin{solution} 
The zero vector forms a trivial subspace, \(\WW=\{\ov\}\)\,:  firstly, \(\ov\in\WW\);
secondly, the only vector in~\WW\ is \(\uv=\ov\) for which every scalar multiple \(c\uv=c\ov=\ov\in\WW\);
and thirdly, a second vector~\vv\ in~\WW\ can only be \(\vv=\ov\) so \(\uv+\vv=\ov+\ov=\ov\in\WW\).
The three requirements of \cref{def:subspace} are met, and so \(\{\ov\}\) is always \text{a subspace.}

\end{solution}

\item\label[example]{eg:somsubsg} \(\RR^n\).
\begin{solution} \sloppy
Lastly, \(\RR^n\) also is a subspace:
firstly, \(\ov=(0,0,\ldots,0)\in\RR^n\);
secondly, for \(\uv=(\hlist un)\in\RR^n\), the scalar multiplication \(c\uv=c(\hlist un) =(\hlist{cu}n)\in\RR^n\);
and thirdly, for \(\vv=(\hlist vn)\in\RR^n\), the vector addition \(\uv+\vv=(\hlist un)+(\hlist vn) =(u_1+v_1,u_2+v_2,\ldots,u_n+v_n)\in\RR^n\).
The three requirements of \cref{def:subspace} are met, and so \(\RR^n\) is always \text{a subspace.}
\end{solution}

\end{enumerate}
\end{example}


\begingroup
\def\temp{\begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize
    ,axis equal image, axis lines=middle, grid ] 
    \addplot[blue,thick,domain=-2.1:2.1] {x^3/4};
\end{axis} \end{tikzpicture}}
\needlines6
\begin{activity}[\temp]
The following pairs of vectors are all in the set shown to the right (in the sense that their end-points lie on the plotted curve).  
The sum of which pair proves that the curve plotted to the right is not a subspace?
\actposs{\((-1,-\frac14)\clb (2,2)\)}
{\((0,0)\clb (2,2)\)}
{\((2,2)\clb (-2,-2)\)}
{\((1,\frac14)\clb (0,0)\)}
\end{activity}
\endgroup



In summary:
\begin{itemize}
\item in two dimensions (denoted~\(\RR^2\)), subspaces are the origin~\(\{\ov\}\), any line through~\ov, or the entire plane~\(\RR^2\);
\item in three dimensions (denoted~\(\RR^3\)), subspaces are the origin~\(\{\ov\}\), any line through~\ov, any plane through~\ov, or the entire space~\(\RR^3\);
\item and analogously for higher dimensions (denoted~\(\RR^n\)).
\end{itemize}


Recall that the set of all linear combinations of a set of vectors, such as \((-2,1,0,0)s+(-\frac{15}7,0,\frac97,1)t\) (\cref{eg:homosysiv}), is called the span of that set (\cref{def:span}).

\begin{theorem} \label{thm:spansubs} 
Let \hlist\wv k\ be \(k\)~vectors in~\(\RR^n\),
then \(\Span\{\hlist\wv k\}\) is a \idx{subspace} of~\(\RR^n\).
\end{theorem}

\begin{proof}
Denote \(\Span\{\hlist\wv k\}\) by~\WW; we prove it is a subspace (\cref{def:subspace}).
First, \(\ov=0\wv_1+0\wv_2+\cdots+0\wv_k\) which is a linear combination of \hlist\wv k\,, and so the zero vector \(\ov\in\WW\).
Now let \(\uv,\vv\in\WW\) then by \cref{def:span} there are coefficients \hlist an\ and \hlist bn\ such that
\begin{eqnarray*}
&&\uv=\lincomb a\wv k\,,
\\&&\vv=\lincomb b\wv k\,.
\end{eqnarray*}
Secondly, consequently
\begin{eqnarray*}
\uv+\vv&=&
\lincomb a\wv k
\\&&{}+\lincomb b\wv k
\\&=&(a_1+b_1)\wv_1+(a_2+b_2)\wv_2+\cdots+(a_k+b_k)\wv_k\,,
%\\&\in&\Span\{\hlist\wv k\}=\WW.
\end{eqnarray*}
which is a linear combination of \hlist\wv k\,, and so is in~\WW.
Thirdly, for every scalar~\(c\),
\begin{equation*}
c\uv=c(\lincomb a\wv k)
=\lincomb {ca}\wv k\,,
%\\&\in&\Span\{\hlist\wv k\}=\WW.
\end{equation*}
which is a linear combination of \hlist\wv k\,, and so is in~\WW.
Hence \(\WW=\Span\{\hlist\wv k\}\) is a subspace.
\end{proof}


\begin{example} \label{eg:1x2subs}
\(\Span\{(1,\frac12)\}\) is the subspace \(y=x/2\).
The reason is that a vector \(\uv\in\Span\{(1,\frac12)\}\) only if there is some constant~\(a_1\) such that \(\uv=a_1(1,\frac12)=(a_1,a_1/2)\).
That is, the \(y\)-component is half the \(x\)-component and hence it lies on the line \(y=x/2\).

\(\Span\{(1,\frac12)\clb (-2,-1)\}\) is also the subspace \(y=x/2\) since every linear combination \(a_1(1,\frac12)+a_2(-2,-1)=(a_1-2a_2,a_1/2-a_2)\) satisfies that the \(y\)-component is half the \(x\)-component and hence the linear combination lies on the line \(y=x/2\).
\end{example}

\needlines7
\begin{wrapfigure}r{0pt}
\qview{28}{32} {\begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize
    ,axis equal image  ,view={\q}{30}  ] 
    \addplot3[surf,samples=9,opacity=0.4] {-x/6+y/3};
    \addplot3[blue!50!black,thick,quiver={u=3,v=3,w=1/2},-stealth] coordinates {(0,0,0)};
    \addplot3[blue!50!black,thick,quiver={u=0,v=3,w=1},-stealth] coordinates {(0,0,0)};
\end{axis}
\end{tikzpicture}}
\end{wrapfigure}
\begin{example} \label{eg:plsubs}
The plane \(z=-x/6+y/3\) may be written as \(\Span\{(3,3,1/2)\clb (0,3,1)\}\), as illustrated in stereo to the right, since every \idx{linear combination} of these two vectors fills out the plane: \(a_1(3,3,1/2)+a_2(0,3,1) =(3a_1,3a_1+3a_2,a_1/2+a_2)\) and so lies in the plane as \(-x/6+y/3-z=-\frac163a_1+\frac13(3a_1+3a_2)-(a_1/2+a_2) =-\frac12a_1+a_1+a_2-\frac12a_1-a_2=0\) for all \(a_1\) and~\(a_2\) (although such arguments do not establish that the linear combinations cover the whole plane---we need \cref{thm:homosubsp}).

\needlines9
\begin{wrapfigure}r{0pt}
\qview{28}{32} {\begin{tikzpicture} 
\begin{axis}[small,font=\footnotesize
    ,axis equal image  ,view={\q}{35}  ] 
    \addplot3[surf,samples=9,opacity=0.4] {-x/6+y/3};
    \addplot3[blue!50!black,thick,quiver={u=5,v=1,w=-1/2},-stealth] coordinates {(0,0,0)};
    \addplot3[blue!50!black,thick,quiver={u=0,v=-3,w=-1},-stealth] coordinates {(0,0,0)};
    \addplot3[blue!50!black,thick,quiver={u=-4,v=1,w=1},-stealth] coordinates {(0,0,0)};
\end{axis}
\end{tikzpicture}}
\end{wrapfigure}
Also,  \(\Span\{(5,1,-1/2)\clb (0,-3,-1)\clb (-4,1,1)\}\) is the  plane \(z=-x/6+y/3\), as illustrated to the right. 
The reason is that every \idx{linear combination} of these three vectors fills out the plane: \(a_1(5,1,-1/2)+a_2(0,-3,-1)+a_3(-4,1,1) =(5a_1-4a_3, a_1-3a_2+a_3, -a_1/2-a_2+a_3)\) and so lies in the plane as \(-x/6+y/3-z=-\frac16(5a_1-4a_3)+\frac13(a_1-3a_2+a_3)-(-a_1/2-a_2+a_3) =-\frac56a_1+\frac23a_3+\frac13a_1-a_2+\frac13a_3+\frac12a_1+a_2-a_3 =0\) for all \(a_1\), \(a_2\), and~\(a_3\).
\aqed

\end{example}

\needlines5
\begin{wrapfigure}[5]r{0pt}
\qview{28}{32} {\begin{tikzpicture} 
\begin{axis}[small,font=\footnotesize,domain=-3:3
    ,axis equal image  ,view={\q}{30}  ] 
    \addplot3[surf,samples=9,opacity=0.4] {-x/3+y*2/3};
    \addplot3[blue!50!black,thick,quiver={u=+2,v=1,w=0},-stealth] coordinates {(0,0,0)};
    \addplot3[blue!50!black,thick,quiver={u=-3,v=0,w=1},-stealth] coordinates {(0,0,0)};
\end{axis}
\end{tikzpicture}}
\end{wrapfigure}
\begin{example} \label{eg:planesubs}
Find a set of two vectors that spans the plane \(x-2y+3z=0\)\,.
\begin{solution} 
Write the equation for this plane as \(x=2y-3z\)\,, say, then vectors in the plane are all of the form \(\uv=(x,y,z)=(2y-3z,y,z) =(2,1,0)y+(-3,0,1)z\)\,.
That is, all vectors in the plane may be written as a linear combination of the two vectors \((2,1,0)\) and~\((-3,0,1)\),
hence the plane is \(\Span\{(2,1,0)\clb (-3,0,1)\}\) as illustrated in stereo to the right. 
\aqed
\end{solution}

\end{example}



Such subspaces connect with matrices.
The connection is via a matrix whose columns are the vectors appearing within the span,
although sometimes we also use the rows of the matrix to be the vectors in \text{the span.}


\begin{definition}\label{def:colsp} 
For every $m\times n$ matrix~$A$:
    \begin{enumerate}[ref=\ref{def:colsp}(\alph*)]
        \item\label[definition]{def:colspa} the \bfidx{column space} of~\(A\) is the \idx{subspace} of~$\RR^m$ \idx{span}ned by the \(n\)~\idx{column vector}s of~$A$;%
        \footnote{Some of you may know that the column space is also called the \idx{range}, but for the moment we just use the term column space. \ifcsname r@ch:cipvs\endcsname \cref{ch:cipvs} establishes and discusses this connection between column space and range.\fi}
        
		\item\label[definition]{def:colspb} the \bfidx{row space} of~$A$ is the \idx{subspace} of~$\RR^n$ \idx{span}ned by the \(m\)~\idx{row vector}s (transposed) of~$A$.  
    \end{enumerate}
\end{definition}


\begin{example} 
\cref{eg:1x2subs,eg:plsubs,eg:planesubs} provide some cases.
\begin{itemize}
\item 
\begin{figbox}{\begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize
    ,xlabel={$x$},ylabel={$y$}
    ,axis equal image, axis lines=middle] 
    \addplot[blue,thick] {-2*x};
\end{axis}
\end{tikzpicture}}%
From \cref{eg:1x2subs}, the \idx{column space} of \(A=\begin{bmat} 1&-2\\1/2&-1 \end{bmat}\) is the line \(y=x/2\)\,.

The \idx{row space} of this matrix~\(A\) is \(\Span\{(1,-2)\clb (\frac12,-1)\}\).
This row space is the set of all vectors of the form \((1,-2)s+(\frac12,-1)t=(s+t/2,-2s-t)=(1,-2)(s+t/2)=(1,-2)t'\) is the line \(y=-2x\) as illustrated to the right.
That the row space and the column space are both lines, albeit different lines, is not a coincidence (\cref{thm:rowcolD}).
\end{figbox}


\item \cref{eg:plsubs} shows that the \idx{column space} of matrix
\begin{equation*}
B=\begin{bmatrix} 3&0\\3&3\\\frac12&1 \end{bmatrix}
\end{equation*}
is the plane \(z=-x/6+y/3\) in~\(\RR^3\).

\begin{figbox}{\begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize,ymin=-1.5,ymax=3.5
    ,xlabel={$x$},ylabel={$y$}
    ,axis equal, axis lines=middle ] 
    \addplot[blue,thick,quiver={u=3,v=0},-stealth] coordinates {(0,0)};
    \addplot[blue,thick,quiver={u=3,v=3},-stealth] coordinates {(0,0)};
    \addplot[blue,thick,quiver={u=1/2,v=1},-stealth] coordinates {(0,0)};
\end{axis}
\end{tikzpicture}}%
The \idx{row space} of matrix~\(B\) is \(\Span\{(3,0)\clb (3,3)\clb (\frac12,1)\}\) which is a subspace of~\(\RR^2\)---the right-hand plot shows the three vectors. 
% the next word should not be "However"
Whereas the column space is a subspace of~\(\RR^3\).
Here the row space is all of~\(\RR^2\) as for each \((x,y)\in\RR^2\) choose  the linear combination \(\frac{x-y}3(3,0)+\frac{y}3(3,3)+0(\frac12,1)=(x-y+y+0,0+y+0)=(x,y)\) so each \((x,y)\) is in the span, and hence all of the \(\RR^2\)~plane is the span.
That the column space and the row space are both planes is no coincidence (\cref{thm:rowcolD}).
\end{figbox}


\item \cref{eg:plsubs} also shows that the column space of matrix
\begin{equation*}
C=\begin{bmatrix} 5&0&-4\\1&-3&1\\-\frac12&-1&1 \end{bmatrix}
\end{equation*}
is also the plane \(z=-x/6+y/3\) in~\(\RR^3\).

\begin{figbox}{\qview{73}{75}{\begin{tikzpicture} 
\begin{axis}[small,font=\footnotesize,view={\q}{30}
    ,axis equal image    ] 
    \addplot3[surf,samples=9,opacity=0.4] {-0.8*x-0.6*y};
    \addplot3[blue!50!black,thick,quiver={u=5,v=0,w=-4},-stealth] coordinates {(0,0,0)};
    \addplot3[blue!50!black,thick,quiver={u=1,v=-3,w=1},-stealth] coordinates {(0,0,0)};
    \addplot3[blue!50!black,thick,quiver={u=-1/2,v=-1,w=1},-stealth] coordinates {(0,0,0)};
\end{axis}
\end{tikzpicture}}}%
Now, \(\Span\{(5,0,-4)\clb (1,-3,1)\clb (-\frac12,-1,1)\}\) is the \idx{row space} of matrix~\(C\).
It is not readily apparent, but we can check that this space is the plane \(4x+3y+5z=0\)\,, as illustrated to the right in stereo.
To see this, consider all linear combinations \(a_1(5,0,-4)+a_2(1,-3,1)+a_3(-\frac12,-1,1)
=(5a_1+a_2-a_3/2, -3a_2-a_3, -4a_1+a_2+a_3)\) satisfy
\(4x+3y+5z
=4(5a_1+a_2-a_3/2)+3(-3a_2-a_3)+5(-4a_1+a_2+a_3)
=20a_1+4a_2-2a_3-9a_2-3a_3-20a_1+5a_2+5a_3
=0\)\,.
Again, it is no coincidence that the row and column spaces of~\(C\) are both planes (\cref{thm:rowcolD}).

\end{figbox}
\end{itemize}
\end{example}





\begin{activity}
Which one of the following vectors is in the \idx{column space} of the matrix
\begin{equation*}
\begin{bmatrix} 6 &  2
\\  -3 &  5
\\  -2 & -1 \end{bmatrix}?
\end{equation*}
\actposs[4]{\(\begin{bmatrix} 8\\2\\-3 \end{bmatrix}\)}
{\(\begin{bmatrix} 2\\-3\\-3 \end{bmatrix}\)}
{\(\begin{bmatrix} 2\\2\\-3 \end{bmatrix}\)}
{\(\begin{bmatrix} 8\\5\\-2 \end{bmatrix}\)}
\end{activity}




\begin{example} 
Is vector \(\bv=(-0.6,0,-2.1,1.9,1.2)\) in the \idx{column space} of matrix
\begin{equation*}
A=\begin{bmatrix} 2.8&-3.1&3.4
\\4.0&1.7&0.8
\\-0.4&-0.1&4.4
\\1.0&-0.4&-4.7
\\-0.3&1.9&0.7 \end{bmatrix}?
\end{equation*}
What about vector \(\cv=(15.2,5.4,3.8,-1.9,-3.7)\)?

\begin{solution} 
The question is: can we find a linear combination of the columns of~\(A\) which equals vector~\bv?
That is, can we find some vector~\xv\ of the coefficients in the linear combination such that \(A\xv=\bv\)?
Answer using our knowledge of \text{linear equations.}

Let's use \cref{pro:gensol} in \script.
\begin{enumerate}
\item Compute an \svd\  of this \(5\times 3\) matrix with
\begin{verbatim}
A=[2.8 -3.1  3.4
   4.0  1.7  0.8
  -0.4 -0.1  4.4
   1.0 -0.4 -4.7
  -0.3  1.9  0.7]
[U,S,V]=svd(A)
\end{verbatim}
\setbox\ajrqrbox\hbox{\qrcode{% column space
A=[2.8 -3.1 3.4
 4.0 1.7 0.8
 -0.4 -0.1 4.4
 1.0 -0.4 -4.7
 -0.3 1.9 0.7]
[U,S,V]=svd(A)
z=U'*[-0.6;0;-2.1;1.9;1.2]
z=U'*[15.2;5.4;3.8;-1.9;-3.7]
}}%
\marginajrbox%
to find \twodp
\begin{verbatim}
U =
  -0.58   0.49   0.53  -0.07   0.37
  -0.17   0.69  -0.65  -0.04  -0.25
  -0.56  -0.28  -0.10   0.74  -0.22
   0.57   0.43   0.21   0.66   0.14
  -0.04  -0.15  -0.49   0.10   0.85
S =
   7.52      0      0
      0   4.91      0
      0      0   3.86
      0      0      0
      0      0      0
V = ...
\end{verbatim}

\item Then solve \(U\zv=\bv\) with \verb|z=U'*[-0.6;0;-2.1;1.9;1.2]| to find \twodp\ \(\zv=(2.55,0.92,-0.29,-0.15,1.54)\).

\item Now the diagonal matrix~\(S\) has three nonzero singular values, and the last two rows are zero.
So to be able to solve \(S\yv=\zv\) we need the last two components of~\zv\ to be zero. 
But, at \(-0.15\) and~\(1.54\), they are not zero, so the system is not solvable.
Hence there is no linear combination of the columns of~\(A\) that gives us vector~\bv.
Consequently, vector~\bv\ is not in the column space of~\(A\).

\item For the case of vector~\(\cv=(15.2,5.4,3.8,-1.9,-3.7)\) solve \(U\zv=\cv\) with 
\begin{verbatim}
z=U'*[15.2;5.4;3.8;-1.9;-3.7]
\end{verbatim}
to find \(\zv=(-12.800,9.876,5.533,0.000,0.000)\).
Since the last two entries in vector~\zv\ are zero, corresponding to the zero rows of~\(S\), a solution exists to \(S\yv=\zv\)\,.
Hence a solution exists to \(A\xv=\cv\)\,.
Consequently, vector~\cv\ is in the column space of~\(A\).

\end{enumerate}
(Incidentally, you may check that \(\cv=2\av_1-2\av_2+\av_3\)\,.)
\end{solution}
\end{example}






Another subspace associated with matrices is the set of possible solutions to a homogeneous system of linear equations.


\begin{theorem}\label{thm:homosubsp} 
For any $m\times n$ matrix~$A$, define the set~$\Null(A)$ to be all the solutions~$\xv$ of the \idx{homogeneous} \idx{system} $A\xv=\ov$\,. 
The set~\(\Null(A)\) is a \idx{subspace} of~$\RR^n$ called the \bfidx{nullspace} of~$A$.
\end{theorem}
\begin{proof} 
First, \(A\ov=\ov\) so \(\ov\in\Null A\)\,.
Let \(\uv,\vv\in\Null A\)\,; that is, \(A\uv=\ov\) and \(A\vv=\ov\)\,.
Second, by the distributivity of matrix-vector multiplication (\cref{thm:pmm}), \(A(\uv+\vv)=A\uv+A\vv=\ov+\ov=\ov\) and so \(\uv+\vv\in\Null A\)\,.
Third, by the associativity and commutativity of \emph{scalar} multiplication (\cref{thm:pasm}), for every \(c\in\RR\)\,, \(A(c\uv)=Ac\uv=cA\uv=c(A\uv)=c\ov=\ov\) and so \(c\uv\in\Null A\). 
Hence \(\Null A\) is a subspace (\cref{def:subspace}).
\end{proof}




\begin{example} \label{eg:nullsp}
\begin{itemize}
\item  \cref{eg:homosysi} showed that the only solution of the \idx{homogeneous} system \(\begin{scases}
3x_1-3x_2=0\\-x_1-7x_2=0
\end{scases}\) is \(\xv=\ov\)\,.
Thus its set of solutions is~\(\{\ov\}\) which is a subspace (\cref{eg:somsubsf}).
Thus \(\{\ov\}\) is the \idx{nullspace} of matrix \(\begin{bmat} 3&-3\\-1&-7 \end{bmat}\).

\item Recall that the \idx{homogeneous} system of linear equations from \cref{eg:homosysiv} has solutions \(\xv=(-2s-\frac{15}7t,s,\frac97t,t) =(-2,1,0,0)s+(-\frac{15}7,0,\frac97,1)t\) for arbitrary \(s\) and~\(t\).
That is, the set of solutions is \(\Span\{(-2,1,0,0)\clb (-\frac{15}7,0,\frac97,1)\}\).
Since the set is a span (\cref{thm:spansubs}), the set of solutions is a subspace of~\(\RR^4\).
Thus this set of solutions is the \idx{nullspace} of the matrix \(\begin{bmat} 1&2&4&-3\\
1&2&-3&6 \end{bmat}\).

\item In contrast, \cref{eg:gjeb} shows that the set of solutions of the \emph{non}-homogeneous system \(\begin{scases}
-2v+3w=-1\,,\\2u+v+w=-1\,.
\end{scases}\)
is \((u,v,w)=(-\frac34-\frac14t,\frac12+\frac32t,t)
=(-\frac34,\frac12,0)+(-\frac14,\frac32,1)t\)
over all values of parameter~\(t\).
But there is no value of parameter~\(t\) giving~\ov\ as a solution: for the last component to be zero requires \(t=0\)\,, but when \(t=0\) neither of the other components are zero, so they cannot all be zero.
Since the origin~\ov\ is not in the set of solutions, the set does not form a subspace. 
A \emph{non}-homogeneous system does not form a subspace \text{of solutions.}
\end{itemize}
\end{example}


\begin{example} 
Is the vector \(\vv=(-2,6,1)\) in the null space of~\(A=\begin{bmat} 3&1&0
\\-5&-1&-4 \end{bmat}\)?  
What about vector \(\wv=(1,-3,2)\)?
\begin{solution} 
To test a given vector, just multiply by the matrix and see if the result is zero.
\begin{itemize}
\item \(A\vv=\begin{bmat} 3\cdot(-2)+1\cdot6+0\cdot1
\\-5\cdot(-2)-1\cdot6-4\cdot1 \end{bmat}
=\begin{bmat} 0\\0 \end{bmat}=\ov\), so \(\vv\in\Null A\)\,.
\item \(A\wv=\begin{bmat} 3\cdot1+1\cdot(-3)+0\cdot2
\\-5\cdot1-1\cdot(-3)-4\cdot2 \end{bmat}
=\begin{bmat} 0\\-10 \end{bmat}\neq\ov\), so \wv~is not in the nullspace.
\end{itemize}
\end{solution}
\end{example}


\needlines8
\begin{activity}
Which vector is in the \idx{nullspace} of the matrix
\begin{equation*}
\begin{bmatrix} 4&5&1
\\4&3&-1
\\4&2&-2 \end{bmatrix}?
\end{equation*}
\actposs[4]{\(\begin{bmatrix} 2\\-2\\2 \end{bmatrix}\)}
{\(\begin{bmatrix} -1\\0\\4 \end{bmatrix}\)}
{\(\begin{bmatrix} 0\\1\\3 \end{bmatrix}\)}
{\(\begin{bmatrix} 3\\-4\\0 \end{bmatrix}\)}
\end{activity}
   


\paragraph{Summary} Three common ways that subspaces arise from a matrix are as the \idx{column space}, \idx{row space}, and \idx{nullspace}.


\index{subspace|)}






\subsection{Orthonormal bases form a foundation}
\label{sec:obff}

\index{orthonormal basis|(}
\index{basis!orthonormal|(}

\begin{quoted}{\cite{Cuyt2015}}% [\S5.3]}
The importance of \idx{orthogonal basis} functions in interpolation and approximation cannot be overstated.  
%Problems become numerically better conditioned and formulas simplify.
\end{quoted}

Given that \idx{subspace}s arise frequently in linear algebra, and that there are many ways of representing the same subspace (as seen in some previous examples), is there a `best' way of representing subspaces?
The next definition and theorems largely answer \text{this challenge.}

We prefer to use an \idx{orthonormal set} of vectors to span a \idx{subspace}.
The virtue is that orthonormal sets have many practically useful properties.
Because of their beautiful properties, orthonormal sets underpin \textsc{\idx{jpeg}} images, our understanding of vibrations, reliable \idx{weather forecast}ing, and much more.
Recall that an orthonormal set (\cref{def:orthoset}) is composed of vectors that are both all at \idx{right-angles} to each other (their dot products are zero) and all of \text{\idx{unit length}.}


\begin{definition} \label{def:orthobasis} 
An \bfidx{orthonormal basis} for a \idx{subspace}~\WW\ of~\(\RR^n\) is an \idx{orthonormal set} of vectors that span~\WW.
\end{definition}

\begin{example} 
Recall that \(\RR^n\) is itself a subspace of~\(\RR^n\) (\cref{eg:somsubsg}).
\begin{enumerate}
\item The \(n\)~\idx{standard unit vector}s \index{e@$\ev_j$}\hlist\ev n\ in~\(\RR^n\) form a set of \(n\)~orthonormal vectors.
They span the subspace~\(\RR^n\), as every vector in~\(\RR^n\) can be written as a linear combination \(\xv=(\hlist xn)=\lincomb x\ev n\)\,.
Hence the set of standard unit vectors in~\(\RR^n\) is an orthonormal basis for the subspace~\(\RR^n\).

\item The \(n\)~columns \hlist\qv n\ of an \(n\times n\) \idx{orthogonal matrix}~\(Q\) also form an orthonormal basis for the subspace~\(\RR^n\).
The reasons are: first, \cref{thm:orthog:ii} establishes that the \idx{column vector}s of~\(Q\) are orthonormal; and second they span the subspace~\(\RR^n\), as for every vector \(\xv\in\RR^n\) there exists a linear combination \(\xv=\lincomb c\qv n\) obtained by solving \(Q\cv=\xv\) through calculating \(\cv=\tr Q\xv\) since \(\tr Q\)~is the inverse of an orthogonal matrix~\(Q\) (\cref{thm:orthog:i}).
\end{enumerate}
This example also illustrates that generally there are many different orthonormal bases for a given subspace.
\end{example}



\begin{activity}
Which of the following sets is an orthonormal basis for~\(\RR^2\)?
\actposs{\(\{\frac12(1,\sqrt3),\ \frac12(-\sqrt3,1)\}\)}
{\(\{\ov,\iv,\jv\}\)}
{\(\{(1,1)\clb (1,-1)\}\)}
{\(\{\frac15(3,-4),\ \frac1{13}(12,5)\}\)}
\end{activity}



\begin{example} \label{eg:orthbas1}
Find an orthonormal basis for the line \(x=y=z\) in~\(\RR^3\).

\begin{solution} 
\begin{wrapfigure}r{0pt}
\qview{28}{32} {\begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize,domain=-1:1
    ,axis equal image, height=4.5cm ,view={\q}{30}   ] 
  \addplot3[only marks,black] coordinates {(0,0,0)};
  \addplot3[red,samples y=0,thick,opacity=0.8] ({x},{x},{x});
%  \addplot3[blue!50!black,thick,quiver={u=1/sqrt(3),v=1/sqrt(3),w=1/sqrt(3)},-stealth] coordinates {(0,0,0)};
  \threev{0.577}{0.577}{0.577}{}
\end{axis}
\end{tikzpicture}}
\end{wrapfigure}
This line is a subspace as it passes through~\ov.
A parametric description of the line is \(\xv=(x,y,z)=(t,t,t)=(1,1,1)t\) for every~\(t\). 
So the subspace is spanned by~\(\{(1,1,1)\}\)\,.
But this is not an orthonormal basis as it is not of unit length, so divide by its length \(|(1,1,1)|=\sqrt{1^2+1^2+1^2}=\sqrt3\)\,.
That is, \(\{(1/{\sqrt3},1/{\sqrt3},1/{\sqrt3})\}\) is an orthonormal basis for the subspace, as illustrated in stereo to the right.
The only other orthonormal basis is the unit vector in the opposite direction,~\(\{(-1/{\sqrt3},-1/{\sqrt3},-1/{\sqrt3})\}\).
\aqed

\end{solution}
\end{example}


For \idx{subspace}s that are planes in~\(\RR^n\), orthonormal bases have more details to confirm as in the next example.
The \svd\ then empowers us to find such bases as in the next \cref{pro:ospan}.

\begin{wrapfigure}r{0pt}
\qview{28}{32} {\begin{tikzpicture} 
\begin{axis}[small,font=\footnotesize,domain=-1:1
    ,axis equal image ,view={\q}{30}   ] 
    \addplot3[only marks,black] coordinates {(0,0,0)};
    \addplot3[surf,samples=9,opacity=0.4] {-x/2+y};
    \addplot3[blue!50!black,thick,quiver={u=-2/3,v=1/3,w=2/3},-stealth] coordinates {(0,0,0)};
    \addplot3[blue!50!black,thick,quiver={u=2/3,v=2/3,w=1/3},-stealth] coordinates {(0,0,0)};
\end{axis}
\end{tikzpicture}}
\end{wrapfigure}
\begin{example} \label{eg:orthbas2}
Confirm that the plane \(-x+2y-2z=0\) has an orthonormal basis \(\{\uv_1,\uv_2\}\) where \(\uv_1=(-\frac23,\frac13,\frac23)\), and \(\uv_2=(\frac23,\frac23,\frac13)\}\) as illustrated in stereo to the right.

\begin{solution} 
First, the given set is of unit vectors as the lengths are \(|\uv_1|=\sqrt{\frac49+\frac19+\frac49}=1\) and \(|\uv_2|=\sqrt{\frac49+\frac49+\frac19}=1\)\,.
Second, the set is orthonormal as their dot product is zero: \(\uv_1\cdot\uv_2=-\frac49+\frac29+\frac29=0\)\,.
Third, they both lie in the plane as we check by substituting their components in the equation: for~\(\uv_1\), \(-x+2y-2z=\frac23+2(\frac13)-2(\frac23)=\frac23+\frac23-\frac43=0\)\,; and for~\(\uv_2\), \(-x+2y-2z=-\frac23+2(\frac23)-2(\frac23)=-\frac23+\frac43-\frac23=0\)\,.
Lastly, from the parametric form of an equation for a plane (\cref{sec:nvep}) we know that all linear combinations of \(\uv_1\) and~\(\uv_2\) span the plane.
\aqed

\end{solution}
\end{example}





\begin{procedure}[orthonormal basis for a span]\label{pro:ospan}
	Let $\{\hlist\av n\}$ be a set of $n$~vectors in~\(\RR^m\), then the following procedure finds an \idx{orthonormal basis} for the \idx{subspace} \(\Span\{\hlist\av n\}\). 
\begin{enumerate}
\item Form \(m\times n\) matrix $A:= \begin{bmatrix} \av_1 & \av_2& \cdots&\av_n \end{bmatrix}$. 
\item Factorize~\(A\) into an \svd, $A=\usv$. 
Let \(\hlist\uv m\)~denote the \(m\)~columns of~$U$ (\idx{singular vector}s), and let \(r=\rank A\) be the number of nonzero \idx{singular value}s (\cref{def:rank}).  
\item Then \(\{\hlist\uv r\}\) is an \idx{orthonormal basis} for the subspace \(\Span\{\hlist\av n\}\).
\end{enumerate}
\end{procedure}

\begin{proof} 
The argument corresponds to that for \cref{pro:gensol}.
Consider any point \(\bv\in\Span\{\hlist\av n\}\).
Because~\bv\ is in the span, there exist coefficients \hlist xn\ such that
\begin{eqnarray*}
\bv&=&\lincomb \av xn
\\&=&A\xv \quad(\text{by matrix-vector product \cref{sec:amwm}})
\\&=&\usv \xv \quad(\text{by the \svd\ of }A)
\\&=&US \yv \quad(\text{for }\yv=\tr V\xv)
\\&=&U\zv \quad(\text{for }\zv=(\hlist zr,0,\ldots,0)=S\yv)
\\&=&\lincomb \uv z r  \quad(\text{by matrix-vector product})
\\&\in&\Span\{\hlist \uv r\}.
\end{eqnarray*}
These equalities also hold in reverse, due to the invertibility of~\(U\) and~\(V\), and with \(y_i=z_i/\sigma_i\) for \(i=1,2,\ldots,r\)\,.
Hence a point is in \(\Span\{\hlist\av n\}\) if and only if it is in \(\Span\{\hlist \uv r\}\).
Lastly, \(U\)~is an orthogonal matrix and so the set of columns \(\{\hlist \uv r\}\) is an orthonormal set.
Hence \(\{\hlist \uv r\}\) forms an orthonormal basis for \(\Span\{\hlist\av n\}\).
\end{proof}


\begin{example} \label{eg:orthspn2}
Compute an orthonormal basis for \(\Span\{(1,\frac12)\clb(-2,-1)\}\).
\begin{solution} 
Form the matrix whose columns are the given vectors
\(A=\begin{bmat} 1&-2\\1/2&-1 \end{bmat}\),
then ask \script\ for an \svd\ and interpret.
\begin{verbatim}
A=[1 -2; 1/2 -1]
[U,S,V]=svd(A)
\end{verbatim}
\setbox\ajrqrbox\hbox{\qrcode{% orthonormal basis
A=[1 -2; 1/2 -1]
[U,S,V]=svd(A)
}}%
\marginajrbox%
The computed \svd\ is (\(V\)~is immaterial here)
\begin{verbatim}
U =
   -0.8944   -0.4472
   -0.4472    0.8944
S =
    2.5000         0
         0    0.0000
V = ...
\end{verbatim}
There is one nonzero singular value---the matrix has rank one---so an orthonormal basis for the span is the first column of matrix~\(U\), namely the set \(\{(-0.89,-0.45)\}\) \twodp.
That is, every vector in \(\Span\{(1,\frac12)\clb (-2,-1)\}\) can be written as \((-0.89,-0.45)t\) for some~\(t\): hence the span is a line.
\end{solution}
\end{example}


\begin{example} \label{eg:orthospan}
Recall that \cref{eg:plsubs} found the plane \(z=-x/6+y/3\) could be written as \(\Span\{(3,3,1/2)\clb (0,3,1)\}\) or as \(\Span\{(5,1,-1/2)\clb (0,-3,-1)\clb (-4,1,1)\}\).
Use each of these spans to find two different orthonormal bases for the~plane.
\begin{solution} 
\begin{itemize}
\item Form the matrix whose columns are the given vectors
\(A=\begin{bmat} 3&0\\3&3\\1/2&1 \end{bmat}\),
then ask \script\ for the \svd\ and interpret.
In \script\ it is often easier to form the matrix by entering the vectors as rows and then transposing (with the dash):
\begin{verbatim}
A=[3 3 1/2;0 3 1]'
[U,S,V]=svd(A)
\end{verbatim}
\setbox\ajrqrbox\hbox{\qrcode{% orthonormal basis
A=[3 3 1/2;0 3 1]'
[U,S,V]=svd(A)
}}%
\marginajrbox%
The computed \svd\ is \twodp
\begin{verbatim}
U =
  -0.51   0.85   0.16
  -0.84  -0.44  -0.31
  -0.20  -0.29   0.94
S =
   4.95      0
      0   1.94
      0      0
V = ...
\end{verbatim}

\begin{figbox}{\qview{28}{32} {\begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize,domain=-1.4:1.4
    ,axis equal image ,view={\q}{30}   ] 
    \addplot3[surf,samples=9,opacity=0.4] {-x/6+y/3};
    \addplot3[red,thick,quiver={u=-0.51,v=-0.84,w=-0.20},-stealth] coordinates {(0,0,0)};
    \addplot3[red,thick,quiver={u=0.85,v=-0.44,w=-0.29},-stealth] coordinates {(0,0,0)};
    \addplot3[brown!70!black,thick,quiver={u=-0.99,v=-0.01,w=0.16},-stealth] coordinates {(0,0,0)};
    \addplot3[brown!70!black,thick,quiver={u=-0.04,v=-0.95,w=-0.31},-stealth] coordinates {(0,0,0)};
\end{axis}
\end{tikzpicture}}}%
There are two nonzero singular values---the matrix has rank two---so an orthonormal basis for the plane is the set of the first two columns of matrix~\(U\), namely  \((-0.51,-0.84,-0.20)\) and \((0.85,-0.44,-0.29)\).
These basis vectors are illustrated as the pair of red vectors in \text{stereo above-right.}
\reParshape
\end{figbox}

\item Similarly, form the matrix 
\(B=\begin{bmat} 5&0&-4\\1&-3&1\\-1/2&-1&1 \end{bmat}\),
then ask \script\ for the \svd\ and interpret.
Form the matrix in \script\ by entering the vectors as rows and then transposing:
\begin{verbatim}
B=[5 1 -1/2; 0 -3 -1; -4 1 1]'
[U,S,V]=svd(B)
\end{verbatim}
\setbox\ajrqrbox\hbox{\qrcode{% orthonormal basis
B=[5 1 -1/2; 0 -3 -1; -4 1 1]'
[U,S,V]=svd(B)
}}%
\marginajrbox%
The computed \svd\ is \twodp
\begin{verbatim}
U =
  -0.99  -0.04   0.16
  -0.01  -0.95  -0.31
   0.16  -0.31   0.94
S =
   6.49      0      0
      0   3.49      0
      0      0   0.00
V = ...
\end{verbatim}
There are two nonzero singular values---the matrix has rank two---so an orthonormal basis for the plane spanned by the three vectors is the set of the first two columns of matrix~\(U\), namely the vectors  \((-0.99,-0.01,0.16)\) and \((-0.04,-0.95,-0.31)\).
These are the pair of brown vectors in the above stereo illustration.
\aqed
\end{itemize} 
\end{solution}
\end{example}




\begin{activity}
The matrix
\begin{equation*}
A=\begin{bmatrix} 4&5&1
\\4&3&-1
\\4&2&-2 \end{bmatrix}
\end{equation*}
has the following \svd\ computed by \verb|[U,S,V]=svd(A)| in \script: what is an orthonormal basis for the \idx{column space} of the matrix~\(A\) \twodp?
\begin{verbatim}
U =
  -0.67   0.69   0.27
  -0.55  -0.23  -0.80
  -0.49  -0.69   0.53
S =
   9.17      0      0
      0   2.83      0
      0      0   0.00
V =
  -0.75  -0.32  -0.58
  -0.66   0.49   0.58
   0.09   0.81  -0.58
\end{verbatim}
\actposs[1]{\(\{(-0.67,-0.55,-0.49)\clb (0.69,-0.23,-0.69)\}\)}
{\(\{(-0.67,0.69,0.27)\clb (-0.55,-0.23,-0.80)\}\)}
{\(\{(-0.75,-0.32,-0.58)\clb (-0.66,0.49,0.58)\}\)}
{\(\{(-0.75,-0.66,0.09)\clb (-0.32,0.49,0.81)\}\)}
Extension: recalling \cref{thm:ranktr}, which of the above is an orthonormal basis for the \idx{row space} of~\(A\)?
\end{activity}




\begin{example}[\idx{data reduction}] \label{eg:orthbapp}
Every four or five years the phenomenon of \idx{El Ni\~no} makes a large impact on the world's weather: from drought in Australia to floods in South America.
We would like to predict El Ni\~no in advance to save lives and businesses.
El Ni\~no is correlated significantly with the difference in atmospheric pressure between Darwin and Tahiti---the so-called \idx{Southern Oscillation Index} (\soi).
This example seeks patterns in the \soi\ in order to be able to predict the \soi\ and hence predict El Ni\~no.

\begin{figure}
\centering
\input{Matrices/soiRoundData.ltx}
\caption{Yearly average \soi\ over \(50\)~years (`smoothed' somewhat for the purposes of the example).  
The nearly regular behaviour suggests that it should be predictable.}
\label{fig:soiRoundData}
\end{figure}

\cref{fig:soiRoundData} plots the yearly average \soi\ each year for fifty years up to 1993.
A strong regular structure is apparent, but there are significant variations and complexities in the year-to-year signal.
The challenge of this example is to explore the full details of \text{this signal.}

\begin{figure}
\centering
\input{Matrices/soiRoundWind.ltx}
\caption{The first six windows of the \soi\ data of \cref{fig:soiRoundData}---displaced vertically for clarity. 
Each window is of length ten years: 
lowest, the first window is data 1944--1953;
second lowest, covers 1945--1954;
third lowest, covers 1946--1955; 
and so on to the 41st window which is data 1984--1993, \text{not shown.}}
\label{fig:soiRoundWind}
\end{figure}

Let's use a general technique called \idx{Singular Spectrum Analysis}.
The figure shows that the \soi\ oscillates, to and fro, a couple of times every ten years.
This suggests that if we analyse ten year `snapshots', or `windows', of the \soi\ data then there should be some common pattern of oscillations apparent---somehow.
Consider a window of ten years of the \soi, and let the window `slide' across the data to give us many `local' pictures of the evolution in time.
For example, \cref{fig:soiRoundWind} plots six windows (each displaced vertically for clarity) each of length ten years.
As the `window' slides across the fifty year data of \cref{fig:soiRoundData} there are \(41\)~such local views of the data of length ten years.
Let's invoke the concept of \idx{subspace}s to detect regularity in the data via \text{these windows.}

The fundamental property is that if the data has regularities, then it should lie in some \idx{subspace}.
We detect such subspaces using the \svd\ of a matrix.
\begin{itemize}
\item First, form the \(41\)~data windows of length ten into a matrix of size \(10\times 41\).
The numerical values of the \soi\ data of \cref{fig:soiRoundData} are the following:
\begin{verbatim}
year=(1944:1993)'
soi=[-0.03; 0.74; 6.37; -7.28; 0.44; -0.99; 1.32
6.42; -6.51; 0.07; -1.96; 1.72; 6.49; -5.61
-0.24; -2.90; 1.92; 6.54; -4.61; -0.47; -3.82
1.94; 6.56; -3.53; -0.59; -4.69; 1.76; 6.53
-2.38; -0.59; -5.48; 1.41; 6.41; -1.18; -0.45
-6.19; 0.89; 6.19; 0.03; -0.16; -6.78; 0.21; 5.84
1.23; 0.30; -7.22; -0.60; 5.33; 2.36; 0.91 ] 
\end{verbatim}

\item Second, form the \(10\times41\) matrix of the windows of the data, the first seven columns being
\begin{verbatim}
A =
 Columns 1 through 7
-0.03   0.74   6.37  -7.28   0.44  -0.99   1.32
 0.74   6.37  -7.28   0.44  -0.99   1.32   6.42
 6.37  -7.28   0.44  -0.99   1.32   6.42  -6.51
-7.28   0.44  -0.99   1.32   6.42  -6.51   0.07
 0.44  -0.99   1.32   6.42  -6.51   0.07  -1.96
-0.99   1.32   6.42  -6.51   0.07  -1.96   1.72
 1.32   6.42  -6.51   0.07  -1.96   1.72   6.49
 6.42  -6.51   0.07  -1.96   1.72   6.49  -5.61
-6.51   0.07  -1.96   1.72   6.49  -5.61  -0.24
 0.07  -1.96   1.72   6.49  -5.61  -0.24  -2.90
\end{verbatim}
\cref{fig:soiRoundWind} plots the first six of these columns.
The simplest way to form this matrix in \script---useful for all such shifting windows of data---is to invoke the \index{hankel()@\texttt{hankel()}}\verb|hankel()| function:
\begin{verbatim}
A=hankel(soi(1:10),soi(10:50))
\end{verbatim}
In \script\ the command \index{hankel()@\texttt{hankel()}}\verb|hankel(s(1:w),s(w:n))| forms the \(w\times(n-w+1)\) so-called \idx{Hankel matrix}
\begin{equation*}
\begin{bmatrix} s_1&s_2&s_3&\cdots&s_{n-w}&s_{n-w+1}
\\s_2&s_3&\vdots&&s_{n-w+1}&\vdots
\\s_3&\vdots&s_w&&\vdots&\vdots
\\\vdots&s_w&s_{w+1}&&\vdots&s_{n-1}
\\s_w&s_{w+1}&s_{w+2}&\cdots&s_{n-1}&s_n \end{bmatrix}
\end{equation*}

\item Lastly, compute the \svd\ of the matrix of these windows:
\begin{verbatim}
[U,S,V]=svd(A);
singValues=diag(S)
plot(U(:,1:4))
\end{verbatim}
\setbox\ajrqrbox\hbox{\qrcode{% SOI SSA
year=(1944:1993)'
soi=[-0.03; 0.74; 6.37; -7.28; 0.44; -0.99; 1.32
6.42; -6.51; 0.07; -1.96; 1.72; 6.49; -5.61
-0.24; -2.90; 1.92; 6.54; -4.61; -0.47; -3.82
1.94; 6.56; -3.53; -0.59; -4.69; 1.76; 6.53
-2.38; -0.59; -5.48; 1.41; 6.41; -1.18; -0.45
-6.19; 0.89; 6.19; 0.03; -0.16; -6.78; 0.21; 5.84
1.23; 0.30; -7.22; -0.60; 5.33; 2.36; 0.91 ]
A=hankel(soi(1:10),soi(10:50))
[U,S,V]=svd(A);
singValues=diag(S)
plot(U(:,1:4))
}}%
\marginajrbox%
The computed singular values are $44.63,$ $43.01,$ $39.37,$ $36.69,$ $0.03,$ $0.03,$ $0.02,$ $0.02,$ $0.02,$ $0.01$.
In practice, treat the six small singular values as zero.
Since there are four `nonzero' singular values, the windows of data lie in a subspace spanned by the first four columns of~\(U\).
\begin{figure}
\centering
\input{Matrices/soiRoundSubs.ltx}
\caption{The first four singular vectors of the \soi\ data---displaced vertically for clarity.  
The bottom two form a pair to show a five-year cycle.  
The top two are a pair that show a two--three-year cycle.  
The combination of these two cycles leads to the structure of the \soi\ in \cref{fig:soiRoundData}.}
\label{fig:soiRoundSubs}
\end{figure}%
\end{itemize}
That is, all the structure seen in the fifty year \soi\ data of \cref{fig:soiRoundData} can be expressed in terms of the  orthonormal basis of the four ten-year vectors plotted in \cref{fig:soiRoundSubs}.
This analysis implies that the \soi\ data is composed of two cycles of two different frequencies.%
\footnote{However, I `smoothed' the \soi\ data for the purposes of this example.  The real \soi\ data is much noisier.  
Also we would use \(600\)~monthly averages not \(50\)~yearly averages: so a ten-year window would be a window of \(120\)~months, and the matrix would be considerably larger \(120\times481\).  
Nonetheless, the conclusions with the real data---and justified by \cref{ch:am}---are much the same.}
\end{example}



\cref{eg:orthospan} obtained two different orthonormal bases for the one plane.  
Although the bases are different, they both had the same number of vectors.
The next theorem establishes that this same number \text{always occurs.}

\begin{theorem} \label{thm:sameD} 
For every given \idx{subspace}, any two \index{orthonormal basis}orthonormal bases have the same number of vectors.
\end{theorem}
\begin{proof} 
Let \(\cU=\{\hlist\uv r\}\), with \(r\)~vectors, and \(\cV=\{\hlist\vv s\}\), with \(s\)~vectors, be any two orthonormal bases for a given subspace in~\(\RR^n\).
Prove that the number of vectors \(r=s\) by \idx{contradiction}.
First assume \(r<s\) (\cU\ has less vectors than~\cV).
Since \cU\ is an orthonormal basis for the subspace every vector in~\cV\ can be written as a linear combination of vectors in~\cU\ with some coefficients~\(a_{ij}\):
\begin{eqnarray*}
  &&\vv_1=\uv_1a_{11}+\uv_2a_{21}+\cdots+\uv_ra_{r1}\,,
\\&&\vv_2=\uv_1a_{12}+\uv_2a_{22}+\cdots+\uv_ra_{r2}\,,
\\&&\qquad\vdots
\\&&\vv_s=\uv_1a_{1s}+\uv_2a_{2s}+\cdots+\uv_ra_{rs}\,.
\end{eqnarray*}
Write each of these equations, such as the first one, in the form
\begin{equation*}
\vv_1=\begin{bmatrix} \uv_1&\uv_2&\cdots&\uv_r \end{bmatrix}
\begin{bmatrix} a_{11}\\a_{21}\\\vdots\\a_{r1} \end{bmatrix}
=U\av_1\,,
\end{equation*}
upon setting matrix \(U:=\begin{bmatrix} \uv_1&\uv_2&\cdots&\uv_r \end{bmatrix}\).
Then setting the \(n\times s\) matrix
\begin{eqnarray*}
V&:=&\begin{bmatrix} \vv_1&\vv_2&\cdots&\vv_s \end{bmatrix}
\\&=&\begin{bmatrix} U\av_1& U\av_2&\cdots&U\av_s\end{bmatrix}
\\&=&U\begin{bmatrix} \av_1& \av_2&\cdots&\av_s\end{bmatrix}
=UA
\end{eqnarray*}
for the \(r\times s\) matrix~\(A:=\begin{bmatrix} \av_1& \av_2&\cdots&\av_s \end{bmatrix}\).
By assumption, \(r<s\) and so \cref{thm:feweqns} assures us that the homogeneous system \(A\xv=\ov\) has infinitely many solutions, choose any one non-trivial solution \(\xv\neq\ov\)\,.
Consider 
\begin{eqnarray*}
V\xv&=& UA\xv\quad(\text{from above})
\\&=&U\ov\quad(\text{since }A\xv=\ov)
\\&=&\ov\,.
\end{eqnarray*}
Premultiplying \(V\xv=\ov\) by~\(\tr V\) gives \(\tr VV\xv=\tr V\ov\), but as the columns of~\cV\ are orthonormal this simplifies to \(I_s\xv=\ov\)\,; that is, \(\xv=\ov\)\,.  
But \(\xv=\ov\) contradicts \(\xv\neq\ov\)\,, so the assumption cannot be correct, that is, we cannot have \(r<s\)\,.

Second, a corresponding argument establishes that we cannot have \(s<r\)\,.
Hence \(r=s\)\,, and so all orthonormal bases of a given subspace must have the same number of vectors.
\end{proof}







\begin{comment}
Some books do not appear to establish that every subspace is a span of something.  The following argument is similar to Gramm--Schmidt, but not identical.  
\end{comment}

\paragraph{An existential issue} 
How do we know that every \idx{subspace} has an orthonormal basis? 
We know that many subspaces, such as row and column spaces, have an orthonormal basis because they are the span of rows and columns of a matrix, and then \cref{pro:ospan} assures us they have an orthonormal basis.
But do all subspaces have an orthonormal basis?  
The following theorem certifies that \text{they do.}



\begin{theorem}[existence of basis] \label{thm:obaseexists}
Let \WW\ be a \idx{subspace} of~\(\RR^n\), then there exists an orthonormal basis for~\WW.
\end{theorem}

\begin{proof} 
In the trivial case when the subspace is \(\WW=\{\ov\}\), then \(\WW=\Span\{\}\) gives a basis and this trivial case is done.

\begin{wrapfigure}r{0pt}
\qview{28}{32}{\begin{tikzpicture} 
\begin{axis}[small,font=\footnotesize
    ,axis equal image, domain=-1:1.6  ,view={\q}{30}  ] 
    \addplot3[surf,samples=9,opacity=0.4] {-x/6+y/3};
    \node[above] at (axis cs:1.6,-1,-0.5) {$\WW$};
    \addplot3[blue!50!black,thick,quiver={u=0.702,v=0.702,w=0.117},-stealth,mark=o] coordinates {(0,0,0)};
    \node[above] at (axis cs:0.702,0.702,0.117) {$\uv_1$};
    \addplot3[blue] coordinates {(-1,-1,-1/6)(1.5,1.5,1/4)};
\end{axis}
\end{tikzpicture}}
\end{wrapfigure}
For every other subspace \(\WW\neq\{\ov\}\) there exists a nonzero vector \(\wv\in\WW\).
Normalize the vector by setting \(\uv_1=\wv/|\wv|\).
Then all scalar multiples \(c\uv_1=c\wv/|\wv|=(c/|\wv|)\wv\in\WW\) by closure of~\WW\ under scalar multiplication (\cref{def:subspace}). 
Hence \(\Span\{\uv_1\}\subseteq\WW\) (as illustrated to the above-right for example).
Consequently, either  \(\Span\{\uv_1\}=\WW\) and we are done, or we repeat the following step until the space~\WW\ is spanned.

\begin{wrapfigure}r{0pt}
\qview{28}{32}{\begin{tikzpicture} 
\begin{axis}[small,font=\footnotesize
    ,axis equal image, domain=-1:1.6  ,view={\q}{30}  ] 
    \addplot3[surf,samples=9,opacity=0.4] {-x/6+y/3};
    \node[above] at (axis cs:1.6,-1,-0.5) {$\WW$};
    \addplot3[blue!50!black,thick,quiver={u=0.702,v=0.702,w=0.117},-stealth,mark=o] coordinates {(0,0,0)};
    \node[above] at (axis cs:0.702,0.702,0.117) {$\uv_1$};
    \addplot3[blue] coordinates {(-1,-1,-1/6)(1.5,1.5,1/4)};
    \addplot3[blue!50!black,thick,quiver={u=0,v=1.5,w=1/2},-stealth] coordinates {(0,0,0)};
    \node[left] at (axis cs:0,1.5,0.5) {$\wv$};
    \addplot3[red!70!black, thick, quiver={u=-0.187,v=-0.941,w=-0.282},-stealth] coordinates {(0,0,0)};
    \node[right] at (axis cs:-0.187,-0.941,-0.282) {$\uv'_1$};
    \addplot3[red!70!black, thick, quiver={u=0.969,v=-0.131,w=-0.205},-stealth] coordinates {(0,0,0)};
    \node[right] at (axis cs:0.969,-0.131,-0.205) {$\uv'_2$};
\end{axis}
\end{tikzpicture}}
\end{wrapfigure}
Given orthonormal vectors \hlist\uv k\ such that the set \(\Span\{\hlist\uv k\}\subset\WW\), so \(\Span\{\hlist\uv k\}\neq\WW\).  
Then there must exist a vector \(\wv\in\WW\) which is not in the set \(\Span\{\hlist\uv k\}\).
By the closure of subspace~\WW\ under addition and scalar multiplication (\cref{def:subspace}), the set \(\Span\{\hlist\uv k,\wv\}\subseteq\WW\).
\cref{pro:ospan}, on the orthonormal basis for a span, then assures us that an \svd\ gives an orthonormal basis \(\{\hlist{\uv'}{k+1}\}\) for the set \(\Span\{\hlist\uv k,\wv\}\subseteq\WW\) (as illustrated for an example).
Consequently, either \(\Span\{\hlist{\uv'}{k+1}\}=\WW\) and we are done, or we repeat the process of this paragraph with \(k\)~bigger \text{by one.}

The process must terminate because \(\WW\subseteq\RR^n\). 
If the process repeats until \(k=n\)\,, then we know \(\WW=\RR^n\) and we are done as \(\RR^n\) is spanned by the \(n\)~standard unit vectors.
\end{proof}





\paragraph{Ensemble simulation makes better weather forecasts}
Near the end of the twentieth century \idx{weather forecast}s were becoming amazingly good at predicting the chaotic weather days in advance.
However, there were notable failures: occasionally the weather forecast would give no hint of storms that developed (such as the severe 1999 storm in Sydney\footnote{\url{http://en.wikipedia.org/wiki/1999_Sydney_hailstorm} [Oct 2019]}).
Why?

Occasionally the weather is both near a `\idx{tipping point}' where small changes may cause a storm, and where the errors in measuring the current weather are of the magnitude of the necessary changes.
Then the storm would be within the possibilities. 
But the storm would not be forecast if the measurements were, by chance error, the `other side' of the tipping point (as happened in 1999).
Meteorologists now mostly overcome this problem by executing on their computers an \idx{ensemble of simulations}, perhaps an ensemble of a hundred different forecast simulations \cite[pp.274--80, e.g.]{Roulstone2013}.
Such a set of \(100\)~simulations essentially lie in a \idx{subspace} spanned by \(100\)~vectors in the vastly larger space, say~\(\RR^{1,000,000,000}\), of the maybe billion variables in the weather model.
But what happens in the computational simulations is that the ensemble of simulations degenerate in time.
To avoid such degeneracy, the meteorologists continuously `renormalize' the \idx{ensemble of simulations} by rewriting the ensemble in terms of an \emph{orthonormal basis} of \(100\)~vectors.
Such an orthonormal basis for the ensemble reasonably ensures that unusual storms are retained in the range of possibilities explored by the ensemble forecast, and hence make weather forecasting much \text{more complete.}


\index{orthonormal basis|)}
\index{basis!orthonormal|)}



\subsection{Is it a line? a plane? The dimension answers}

\index{dimension|(}

\begin{quoted}{\cite{Mandelbrot1982}}
\ldots\ \emph{physical dimension.} It is an intuitive notion that appears to go back to an archaic state before Greek geometry, yet deserves to be taken up again.
\end{quoted}

\needlines6
\begin{wrapfigure}r{0pt}
\begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize,domain=-1.4:1.4
    ,axis equal image] 
    \addplot3[surf,samples=9,opacity=0.4] {-x/6+y/3};
    \addplot3[red,thick,quiver={u=-0.51,v=-0.84,w=-0.20},-stealth] coordinates {(0,0,0)};
    \addplot3[red,thick,quiver={u=0.85,v=-0.44,w=-0.29},-stealth] coordinates {(0,0,0)};
\end{axis}
\end{tikzpicture} 
\quad
\begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize,domain=-1.4:1.4
    ,axis equal image    ] 
    \addplot3[surf,samples=9,opacity=0.4] {-x/6+y/3};
    \addplot3[brown!70!black,thick,quiver={u=-0.99,v=-0.01,w=0.16},-stealth] coordinates {(0,0,0)};
    \addplot3[brown!70!black,thick,quiver={u=-0.04,v=-0.95,w=-0.31},-stealth] coordinates {(0,0,0)};
\end{axis}
\end{tikzpicture} 
\end{wrapfigure}
One of the beauties of an \idx{orthonormal basis} is that, being orthonormal, they look just like a rotated version of the \idx{standard unit vector}s.
For example, in a \emph{plane} any two orthonormal basis vectors of the plane could form the two `\idx{standard unit vector}s' of a coordinate system in that plane---as suggested by the illustration.
\cref{eg:orthospan} found that the plane \(z=-x/6+y/3\) could have the following two orthonormal bases: either of these orthonormal bases, or indeed any other pair of orthonormal vectors, could act as a pair of `standard unit vectors' of the given \text{planar subspace.}
Similarly in other dimensions for other subspaces.
Just as~\(\RR^n\) is called \(n\)-dimensional and has \(n\)~\idx{standard unit vector}s, so we analogously define the dimension of any subspace.

\begin{definition} \label{def:dim} 
Let \WW\ be a \idx{subspace} of~\(\RR^n\). 
The number of vectors in an \idx{orthonormal basis} for~\WW\ is called the \bfidx{dimension} of~\WW, denoted~\(\dim\WW\).
By convention, \(\dim\{\ov\}=0\)\,.
\end{definition}

\begin{example} 
\begin{itemize}
\item \cref{eg:orthbas1} finds that the linear subspace \(x=y=z\) is spanned by the \idx{orthonormal basis} \(\{(1/{\sqrt3},1/{\sqrt3},1/{\sqrt3})\}\).  
With one vector in the basis, the line is one-dimensional.

\item \cref{eg:orthbas2} finds that the planar subspace \(-x+2y-2z=0\) is spanned by the \idx{orthonormal basis} \(\{\uv_1,\uv_2\}\) where \(\uv_1=(-\frac23,\frac13,\frac23)\), and \(\uv_2=(\frac23,\frac23,\frac13)\).  
With two vectors in the basis, the plane is two-dimensional.

\item  Subspace \(\WW=\Span\{(5,1,-1/2)\clb (0,-3,-1)\clb (-4,1,1)\}\) of \cref{eg:orthospan} is found to have an \idx{orthonormal basis} of  vectors  \((-0.99,-0.01,0.16)\) and \((-0.04,-0.95,-0.31)\).
With two vectors in the basis, the subspace is two-dimensional; that is, \(\dim\WW=2\)\,.

\item Since the subspace~\(\RR^n\) (\cref{eg:somsubsg}) has an \idx{orthonormal basis} of the \(n\)~\idx{standard unit vector}s, \index{e@$\ev_j$}\(\{\hlist\ev n\}\), then  \(\dim\RR^n=n\)\,.

\item The \idx{El Ni\~no} windowed data of \cref{eg:orthbapp} is effectively spanned by four orthonormal vectors.  Despite the apparent complexity of the signal, the data effectively lies in a subspace of dimension four (that of two oscillators).
\end{itemize}
\end{example}


\begin{theorem} \label{thm:rowcolD} 
The \idx{row space} and \idx{column space} of a matrix~\(A\) have the same \idx{dimension}.
Further, given an \svd\ of the matrix, say \(A=\usv\) and setting \(r=\rank A\)\,, an \idx{orthonormal basis} for the column space is the first \(r\)~columns of~\(U\), and that for the \idx{row space} is the first \(r\)~columns of~\(V\).
\end{theorem}

\begin{proof} 
From \cref{def:mattran} of the transpose, the rows of~\(A\) are the same as the columns of~\(\tr A\), and so the row space of~\(A\) is the same as the column space of its transpose,~\(\tr A\).  
Hence,
\begin{align*}
&\text{dimension of the row space of }A
\\&=\text{dimension of the column space of }\tr A
\\&=\rank(\tr A) \quad(\text{by \cref{pro:ospan}})
\\&=\rank A \quad(\text{by \cref{thm:ranktr}})
\\&=\text{dimension of the column space of }A
\quad(\text{by \cref{pro:ospan}}).
\end{align*}
%Hence the row space and the column space have the same dimension.

Let \(m\times n\) matrix~\(A\) have an \svd\ \(A=\usv\) and \(r=\rank A\).
Then \cref{pro:ospan} establishes that an orthonormal basis for the column space of~\(A\) is the first \(r\)~columns of~\(U\).
Recall that \(\tr A=\tr{(\usv)} =V\tr S\tr U\) is an \svd\ for~\(\tr A\) (\cref{thm:ranktr}), and so an orthonormal basis for the column space of~\(\tr A\) is the first \(r\)~columns of~\(V\) (\cref{pro:ospan}).
Since the row space of~\(A\) is the column space of~\(\tr A\), an orthonormal basis for the row space of~\(A\) is the first \(r\)~columns of~\(V\).
\end{proof}


\begin{example} \label{eg:2x2rcsp}
Find an \svd\ of the matrix~\(A=\begin{bmat} 1&-4\\1/2&-2 \end{bmat}\) and compare the \idx{column space} and the \idx{row space} of the matrix.
\begin{solution} 
Ask \script\ for an \svd\ and interpret:
\begin{verbatim}
A=[1 -4; 1/2 -4]
[U,S,V]=svd(A)
\end{verbatim}
\setbox\ajrqrbox\hbox{\qrcode{% orthonormal basis
A=[1 -4; 1/2 -4]
[U,S,V]=svd(A)
}}%
\marginajrbox%
computes the \svd\ 
\begin{verbatim}
U =
  -0.8944  -0.4472
  -0.4472   0.8944
S =
   4.6098        0
        0   0.0000
V =
  -0.2425   0.9701
   0.9701   0.2425
\end{verbatim}
There is one nonzero singular value---the matrix has rank one---so an orthonormal basis for the column space is the first column of matrix~\(U\), namely \((-0.89,-0.45)\) \twodp.

\needlines8
\begin{wrapfigure}r{0pt}
\begin{tikzpicture} 
\begin{axis}[small,font=\footnotesize,domain=-1.5:1.5
%    ,width=16em
    ,axis equal image, axis lines=middle    ] 
    \addplot[samples=2,blue,opacity=0.4,thick] ({-0.89*x},{-0.45*x});
    \addplot[blue,thick,quiver={u=-0.89,v=-0.45},-stealth] coordinates {(0,0)};
    \addplot[samples=2,red,opacity=0.4,thick] ({-0.24*x},{0.97*x});
    \addplot[red,thick,quiver={u=-0.24,v=0.97},-stealth] coordinates {(0,0)};
\end{axis}
\end{tikzpicture}
\end{wrapfigure}
Complementing this, as there is one nonzero singular value---the matrix has rank one---so an orthonormal basis for the row space is the first column of matrix~\(V\), namely \((-0.24,0.97)\).
As illustrated to the right, the two subspaces, the row space (red), and the column space (blue), are different but of the same dimension.
(As in general, here the row and column spaces are \text{not orthogonal.)}
\aqed

\end{solution}
\end{example}



\begin{activity}
Using the \svd\ of \cref{eg:2x2rcsp}, what is the dimension of the \idx{nullspace} of the matrix~\(\begin{bmatrix} 1&-4\\1/2&-2 \end{bmatrix}\)?
\actposs[4]1230
\end{activity}


\begin{example} 
Use the \svd\ of the matrix~\(B\) in \cref{eg:orthospan} to compare the \idx{column space} and the \idx{row space} of matrix~\(B\).

\begin{solution} 
Recall that there are two nonzero singular values---the matrix has rank two---so an orthonormal basis for the column space is  the first two columns of matrix~\(U\), namely the vectors  \((-0.99,-0.01,0.16)\) and \((-0.04,-0.95,-0.31)\).

\begin{wrapfigure}r{0pt}
\qview{58}{62}{\begin{tikzpicture} 
\begin{axis}[small,font=\footnotesize,domain=-1.4:1.4
    ,axis equal image,view={\q}{20}    ] 
    \addplot3[surf,samples=3,blue,opacity=0.3] {-x/6+y/3};
    \addplot3[blue,thick,quiver={u=-0.99,v=-0.01,w=0.16},-stealth] coordinates {(0,0,0)};
    \addplot3[blue,thick,quiver={u=-0.04,v=-0.95,w=-0.31},-stealth] coordinates {(0,0,0)};
    \addplot3[surf,samples=3,red,opacity=0.3] {-0.8*x-0.6*y};
    \addplot3[red,thick,quiver={u=-0.78,v=-0.02,w=0.63},-stealth] coordinates {(0,0,0)};
    \addplot3[red,thick,quiver={u=-0.28,v=0.91,w=-0.32},-stealth] coordinates {(0,0,0)};
\end{axis}
\end{tikzpicture}}
\end{wrapfigure}
Complementing this, as there are two nonzero singular values---the matrix has rank two---so an orthonormal basis for the row space is the set of the first two columns of matrix~\(V\), namely the vectors  \((-0.78,-0.02, 0.63)\) and \((-0.28, 0.91,-0.32)\).
As illustrated to the right in stereo, the two subspaces, the row space~(red) and the column space~(blue), are different but of the same dimension.
\aqed

\end{solution}
\end{example}




\begin{definition} \label{def:nullity} 
The \bfidx{nullity} of a matrix~\(A\) is the \idx{dimension} of its \idx{nullspace} (defined in \cref{thm:homosubsp}), and is denoted by \(\nullity(A)\).
\end{definition}

\begin{example} 
\cref{eg:nullsp} finds the \idx{nullspace} of the two matrices
\begin{equation*}
\begin{bmatrix} 3&-3\\-1&-7 \end{bmatrix}
\quad\text{and}\quad
\begin{bmatrix} 1&2&4&-3\\
1&2&-3&6 \end{bmatrix}.
\end{equation*}
\begin{itemize}
\item The first matrix has nullspace~\(\{\ov\}\) which has dimension zero and hence the \idx{nullity} of the matrix is zero.
\item The second matrix, \(2\times4\), has nullspace written as \(\Span\{(-2,1,0,0)\clb(-\frac{15}7,0,\frac97,1)\}\).
Being spanned by two vectors not proportional to each other, we expect the dimension of the nullspace, the nullity, to be two.
To check, compute the singular values of the matrix whose columns are these vectors: calling the matrix~\(N\) for nullspace,
\begin{verbatim}
N=[-2 1 0 0; -15/7 0 9/7 1]'
svd(N)
\end{verbatim}
\setbox\ajrqrbox\hbox{\qrcode{% dimension
N=[-2 1 0 0; -15/7 0 9/7 1]'
svd(N)
}}%
\marginajrbox%
which computes the singular values
\begin{verbatim}
   3.2485
   1.3008
\end{verbatim}
Since there are two nonzero singular values, there are two orthonormal vectors spanning the subspace, the nullspace, hence its dimension, the nullity, is two.
\aqed

\end{itemize}
\end{example}



\begin{example} \label{eg:nullitysvd}
For the matrix
\begin{equation*}
C=\begin{bmatrix} -1&-2&2&1
\\-3&3&1&0
\\2&-5&1&1 \end{bmatrix},
\end{equation*}
find an \idx{orthonormal basis} for its \idx{nullspace} and hence determine its \idx{nullity}.
\begin{solution} 
To find the nullspace construct a general solution to the homogeneous system \(C\xv=\ov\) with \cref{pro:gensol}.
\begin{enumerate}
\item Enter  into \script\ the matrix~\(C\) and compute an \svd\ via \verb|[U,S,V]=svd(C)| to find \twodp
\setbox\ajrqrbox\hbox{\qrcode{% nullity
C=[-1 -2 2 1
 -3 3 1 0
 2 -5 1 1]
[U,S,V]=svd(C)
}}%
\marginajrbox%
\begin{verbatim}
U =
   0.24   0.78  -0.58
  -0.55   0.60   0.58
   0.80   0.18   0.58
S =
   6.95      0      0      0
      0   3.43      0      0
      0      0   0.00      0
V =
   0.43  -0.65   0.63  -0.02
  -0.88  -0.19   0.42   0.10
   0.11   0.68   0.62  -0.37
   0.15   0.28   0.21   0.92
\end{verbatim}
\item Since the right-hand side of \(C\xv=\ov\) is zero the solution to \(U\zv=\ov\) is \(\zv=\ov\)\,.
\item Then, because the rank of the matrix is two, the solution to \(S\yv=\zv=\ov\) is \(\yv=(0,0,y_3,y_4)\) for free variables \(y_3\) and~\(y_4\).
\item The solution to \(\tr V\xv=\yv\) is \(\sloppy\xv=V\yv=\vv_3y_3+\vv_4y_4
=y_3(0.63,0.42,0.62,0.21)+y_4(-0.02,0.10,-0.37,0.92)\).
\end{enumerate}
Hence  \(\Span\{(0.63,0.42,0.62,0.21)\clb (-0.02,0.10,-0.37,0.92)\}\) is the nullspace of the matrix~\(C\) \twodp.
Because the columns of~\(V\) are orthonormal, the \emph{two} vectors appearing in this span are orthonormal and so form an orthonormal basis for the nullspace.
Hence the \(\nullity C=2\)\,.
\end{solution}
\end{example}



This \cref{eg:nullitysvd} indicates that the \idx{nullity} is determined by the number of \idx{zero column}s in the \idx{diagonal matrix}~\(S\) of an \svd.
Conversely, the rank of a matrix is determined by the number of nonzero columns in the diagonal matrix~\(S\) of an \svd.
Put these two facts together in general and we get the following theorem that helps characterize solutions of \text{linear equations.}





\begin{theorem}[\bfidx{rank theorem}] \label{thm:rank} 
For every \(m\times n\) matrix~\(A\),  \(\rank A+\nullity A=n\)\,, the number of columns of~\(A\).
\end{theorem}
\begin{proof} 
Set \(r=\rank A\)\,.
By \cref{pro:gensol} a {general solution} to the homogeneous system \(A\xv=\ov\) involves \(n-r\) free variables \(y_{r+1},\ldots,y_n\) in the linear combination form \(\vv_{r+1}y_{r+1}+\cdots +\vv_ny_n\)\,.  
Hence the nullspace is \(\Span\{\vv_{r+1},\ldots,\vv_n\}\).
Because matrix~\(V\) is orthogonal, the vectors \(\vv_{r+1},\ldots,\vv_n\) are orthonormal; that is, they form an orthonormal basis for the nullspace, and so the nullspace is of dimension~\(n-r\)\,.
Consequently, \(\rank A+\nullity A=r+(n-r)=n\)\,.
\end{proof}


\begin{example} 
Compute \svd{}s to determine the rank and \idx{nullity} of each of the given matrices.
%for i=1:999,a=round(randn(ceil(1+4*rand(1,2)))*2);if rank(a)<min(size(a)), A=a, svd(A), break, end,end
\begin{Parts}

\item \(\begin{bmatrix} 1&-1&2
\\2&-2&4
 \end{bmatrix}\)
\begin{solution} 
Enter the matrix into \script\ and compute the singular values:
\begin{verbatim}
A=[1 -1 2
2 -2 4]
svd(A)
\end{verbatim}
\setbox\ajrqrbox\hbox{\qrcode{% rank
A=[1 -1 2
2 -2 4]
svd(A)
}}%
\marginajrbox%
The resultant singular values are
\begin{verbatim}
   5.4772
   0.0000
\end{verbatim}
The one nonzero singular value indicates \(\rank A=1\)\,.
Since the matrix has three columns, the nullity---the dimension of the nullspace---is \(3-1=2\)\,. 
\end{solution}

 
\item \(\begin{bmatrix} 1&-1&-1
\\1&0&-1
\\-1&3&1 \end{bmatrix}\)
\begin{solution} 
Enter the matrix into \script\ and compute the singular values:
\begin{verbatim}
B=[1 -1 -1
1 0 -1
-1 3 1]
svd(B)
\end{verbatim}
\setbox\ajrqrbox\hbox{\qrcode{% rank
B=[1 -1 -1
1 0 -1
-1 3 1]
svd(B)
}}%
\marginajrbox%
The resultant singular values are
\begin{verbatim}
   3.7417
   1.4142
   0.0000
\end{verbatim}
The two nonzero singular values indicate  \(\rank B=2\)\,.
Since the matrix has three columns, the nullity---the dimension of the nullspace---is \(3-2=1\)\,. 
\end{solution}


\item \(\begin{bmatrix} 0&0&-1&-3&2
\\-2&-2&1&0&1
\\1&-1&2&8&-2
\\-1&1&0&-2&-2
\\-3&-1&0&-5&1 \end{bmatrix}\)
\begin{solution} 
Enter the matrix into \script\ and compute the singular values:
\begin{verbatim}
C=[0 0 -1 -3 2
 -2 -2 1 -0 1
  1 -1 2 8 -2
 -1 1 -0 -2 -2
 -3 -1 -0 -5 1]
svd(C)
\end{verbatim}
\setbox\ajrqrbox\hbox{\qrcode{% rank
C=[0 0 -1 -3 2
 -2 -2 1 -0 1
 1 -1 2 8 -2
 -1 1 -0 -2 -2
 -3 -1 -0 -5 1]
svd(C)
}}%
\marginajrbox%
The resultant singular values are
\begin{verbatim}
   10.8422
    4.0625
    3.1532
    0.0000
    0.0000
\end{verbatim}
Three nonzero singular values indicate \(\rank C=3\)\,.
Since the matrix has five columns, the nullity---the dimension of the nullspace---is \(5-3=2\)\,. 
\end{solution}


%\item \(\begin{bmatrix} 0&0&-1&-3&2
%\\-2&-2&1&0&1
%\\1&-4&1&-2&1
%\\-1&1&0&-2&-2
%\\-3&-1&0&-5&1 \end{bmatrix}\)
\end{Parts}
\end{example}



\begin{activity}
The matrix
\begin{equation*}
\begin{bmatrix} -2&1&4&0&-4
\\-1&1&0&-2&0
\\-3&1&3&2&-3
\\0&0&1&0&-1 \end{bmatrix}
\text{ has \idx{singular value}s}\quad
\begin{matrix}\tt 8.1975
\\\tt 2.6561
\\\tt 1.6572
\\\tt 0.0000 \end{matrix}
\end{equation*}
computed with \verb|svd()|.
What is its nullity?
\actposs[4]2310
\end{activity}





\begin{example} 
Each of the following graphs plots all the column vectors of a matrix. What is the \idx{nullity} of each of the matrices?  Give reasons.
\begin{enumerate}
\item \begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize
    ,xmax=3.9,ymax=1.4
    ,axis equal image, axis x line=middle, axis y line= middle ] 
    \addplot[blue,thick,quiver={u=3,v=1},-stealth] coordinates {(0,0)};
    \node[right] at (axis cs:3,1) {$\av_1$};
    \addplot[blue,thick,quiver={u=1,v=1},-stealth] coordinates {(0,0)};
    \node[right] at (axis cs:1,1) {$\av_2$};
\end{axis}
\end{tikzpicture}
\begin{solution} 
Zero.
These two column vectors in the plane must come from a \(2\times2\) matrix~\(A\).
Since the two columns are at a non-trivial angle, every point in the plane may be written as a linear combination of \(\av_1\) and~\(\av_2\), hence the column space of~\(A\) is~\(\RR^2\).
Consequently, \(\rank A=2\)\,. 
From the Rank \cref{thm:rank}\index{rank theorem}: \(\nullity A=n-\rank A=2-2=0\)\,. 
\end{solution}


\item \begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize
    ,xmax=1.9,ymax=2.4,ymin=-1.4
    ,axis equal image, axis x line=middle, axis y line= middle ] 
    \addplot[blue,thick,quiver={u=-0.7,v=0.7},-stealth] coordinates {(0,0)};
    \node[left] at (axis cs:-0.5,0.5) {$\bv_1$};
    \addplot[blue,quiver={u=-2,v=2},-stealth] coordinates {(0,0)};
    \node[right] at (axis cs:-2,2) {$\bv_2$};
    \addplot[blue,thick,quiver={u=1,v=-1},-stealth] coordinates {(0,0)};
    \node[right] at (axis cs:1,-1) {$\bv_3$};
\end{axis}
\end{tikzpicture}
\begin{solution} 
Two.
These three column vectors in the plane must come from a \(2\times3\) matrix~\(B\).
The three vectors are all in a line, so the column space of matrix~\(B\) is a line.
Consequently, \(\rank B=1\)\,. 
From the Rank \cref{thm:rank}\index{rank theorem}: \(\nullity B=n-\rank B=3-1=2\)\,. 
\end{solution}


\item 
\qview{30}{35} {
\begin{tikzpicture} 
\begin{axis}[small,font=\footnotesize,view={\q}{30}
    ,xmax=2.9,ymax=2.9,zmax=2.9,xmin=-2.9
    ,axis equal image ]
    \addplot3[blue,thick,quiver={u=1,v=2,w=-2},-stealth] coordinates {(0,0,0)};
    \node[right] at (axis cs:1,2,-2) {$\cv_1$};
    \addplot3[blue,thick,quiver={u=-2,v=2,w=1},-stealth] coordinates {(0,0,0)};
    \node[above] at (axis cs:-2,2,1) {$\cv_2$};
    \addplot3[blue,thick,quiver={u=2,v=1,w=2},-stealth] coordinates {(0,0,0)};
    \node[above] at (axis cs:2,1,2) {$\cv_3$};
    \addplot3[blue,thick,quiver={u=0,v=-2,w=0},-stealth] coordinates {(0,0,0)};
    \node[below] at (axis cs:0,-2,0) {$\cv_4$};
\end{axis}
\end{tikzpicture}}
a \idx{stereo pair}.
\begin{solution} 
One.
These four column vectors in 3D space must come from a \(3\times4\) matrix~\(C\).
Since the four columns do not all lie in a line or plane, every point in space may be written as a linear combination of \(\hlist\cv 4\), hence the column space of~\(C\) is~\(\RR^3\).
Consequently, \(\rank C=3\)\,. 
From the Rank \cref{thm:rank}\index{rank theorem}: \(\nullity C=n-\rank C=4-3=1\)\,. 
\end{solution}

\item 
\qview{30}{35} {
\begin{tikzpicture} 
\begin{axis}[small,font=\footnotesize,view={\q}{30}
    ,axis equal image  ]
    \addplot3[surf,samples=9,opacity=0.4] {-x/5+2*y/5};
    \addplot3[blue,thick,quiver={u=4,v=2,w=0},-stealth] coordinates {(0,0,0)};
    \node[right] at (axis cs:4,2,0) {$\dv_1$};
    \addplot3[blue,thick,quiver={u=0,v=5,w=2},-stealth] coordinates {(0,0,0)};
    \node[right] at (axis cs:0,5,2) {$\dv_2$};
    \addplot3[blue,thick,quiver={u=-5,v=0,w=1},-stealth] coordinates {(0,0,0)};
    \node[below] at (axis cs:-5,0,1) {$\dv_3$};
    \addplot3[blue,thick,quiver={u=3,v=-1,w=-1},-stealth] coordinates {(0,0,0)};
    \node[below] at (axis cs:3,-1,-1) {$\dv_4$};
\end{axis}
\end{tikzpicture}}
a \idx{stereo pair}.
\begin{solution} 
Two.
These four column vectors in 3D space must come from a \(3\times4\) matrix~\(D\).
Since the four columns all lie in a plane (as indicated by the drawn plane), and linear combinations can give every point in the plane, hence the column space of~\(D\) has dimension two.
Consequently, \(\rank D=2\)\,. 
The Rank \cref{thm:rank}\index{rank theorem} gives \(\nullity D=n-\rank D=4-2=2\)\,. 
\end{solution}

\end{enumerate}
\end{example}

Recall the list of exact properties that ensure a system of linear equations has a unique solution, \cref{thm:ftim1}.
The recognition of these new concepts associated with matrices and \idx{linear equation}s lead us to extend \text{this list.}

\begin{theorem}[Unique Solutions: version~2]  \label{thm:ftim2} 
For every \(n\times n\) \idx{square matrix}~\(A\), and extending \cref{thm:ftim1}, the following statements are equivalent:
\begin{enumerate}[ref=\ref{thm:ftim2}(\alph*)]
\item\label[theorem]{thm:ftim2i} \(A\) is \idx{invertible};
\item\label[theorem]{thm:ftim2ii} \(A\xv=\bv\) has a \bfidx{unique solution} for every \(\bv\in\RR^n\);
\item\label[theorem]{thm:ftim2iii} \index{homogeneous}\(A\xv=\ov\) has only the zero solution;
\item\label[theorem]{thm:ftim2iv} all \(n\)~\idx{singular value}s of~\(A\) are nonzero;
\item\label[theorem]{thm:ftim2ivx} the \idx{condition number} of~\(A\) is finite (\(\verb|rcond|>0\));
\item\label[theorem]{thm:ftim2v} \(\rank A=n\)\,;
\item\label[theorem]{thm:ftim2vi} \(\nullity A=0\)\,;
\item\label[theorem]{thm:ftim2vii} the \idx{column vector}s of~\(A\) span~\(\RR^n\);
\item\label[theorem]{thm:ftim2viii} the \idx{row vector}s of~\(A\) span~\(\RR^n\).
\end{enumerate}
\end{theorem}
\begin{proof} 
\cref{thm:ftim1} establishes the equivalence of the statements~\ref{thm:ftim2i}--\ref{thm:ftim2v}.  
We here prove the equivalence of these with the statements~\ref{thm:ftim2vi}--\ref{thm:ftim2viii}.
\begin{description}
\item[\ref{thm:ftim2v}$\iff$\ref{thm:ftim2vi}]
The Rank \cref{thm:rank} assures us that \(\nullity A=0\) if and only if \(\rank A=n\)\,.
\item[\ref{thm:ftim2ii}$\implies$\ref{thm:ftim2vii}] 
By~\ref{thm:ftim2ii} every \(\bv\in\RR^n\) can be written as \(\bv=A\xv\) for some~\xv. 
But \(A\xv\)~is a linear combination of the columns of~\(A\) and so \(\bv\)~is in the span of the columns.  
Hence the column vectors of~\(A\) span~\(\RR^n\).
\item[\ref{thm:ftim2vii}$\implies$\ref{thm:ftim2v}] 
Suppose \(\rank A=r\) reflecting \(r\)~nonzero singular values in an \svd\ \(A=\usv\).
\cref{pro:ospan} assures us the column space of~\(A\) has  orthonormal basis~\(\{\hlist\uv r\}\).
But the column space is~\(\RR^n\) (statement~\ref{thm:ftim2vii}) which also has the orthonormal basis of the \(n\)~standard unit vectors.
\cref{thm:sameD} assures us that the number of basis vectors must be the same; that is, \(\rank A=r=n\)\,.
\item[\ref{thm:ftim2v}$\iff$\ref{thm:ftim2viii}] 
\cref{thm:ranktr} asserts \(\rank(\tr A)=\rank A\),  so the statement~\ref{thm:ftim2v} implies \(\rank(\tr A)=n\), and so statement~\ref{thm:ftim2vii} asserts the columns of~\(\tr A\) span~\(\RR^n\).
But the columns of~\(\tr A\)\ are the rows of~\(A\) so the rows of~\(A\) span~\(\RR^n\).
Conversely, if the rows of~\(A\) span~\(\RR^n\), then so do the columns of~\(\tr A\), hence \(\rank(\tr A)=n\) which by \cref{thm:ranktr} implies \(\rank A=n\)\,.
\end{description}
This completes the extended theorem.
\end{proof}



\index{dimension|)}





\sectionExercises



\begin{exercise}  
Use your intuitive notion of a \idx{subspace} to decide whether each of the following drawn sets (3D in stereo pair) is a subspace, or not.

\begin{Parts}
\item \begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize
    ,axis equal image, axis lines=middle] 
    \addplot[blue,thick] {x*0.7};
\end{axis}
\end{tikzpicture}
\answer{Subspace.}

\item \begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize
    ,axis equal image, axis lines=middle] 
    \addplot[blue,thick,mark=*,samples=11,only marks] {-x*0.7};
\end{axis}
\end{tikzpicture}
\answer{Not a subspace.}

\item \begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize
    ,axis equal image, axis lines=middle ] 
    \addplot[blue,thick] {-1+x};
\end{axis}
\end{tikzpicture}
\answer{Not a subspace.}


\item \begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize
    ,axis equal image, axis lines=middle ] 
    \addplot[blue,thick] {-x+x^2/10};
\end{axis}
\end{tikzpicture}
\answer{Not a subspace.}

\begin{OmitV1}
\item \begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize
    ,axis equal image, axis lines=middle] 
    \addplot[blue,thick] {-x*0.3};
\end{axis}
\end{tikzpicture}
\answer{Subspace.}


\item \begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize,xmin=-2.2,xmax=2.2
    ,axis equal image, axis lines=middle ] 
    \addplot[blue,smooth,samples=30,domain=0:360,thick] ({2*cos(x)},{2*sin(2*x)});
\end{axis}
\end{tikzpicture}
\answer{Not a subspace.}

\item \begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize,xmax=4,ymax=2
    ,axis equal image, axis lines=middle ] 
    \addplot[blue,thick,domain=-5:0] {x*0.8};
    \addplot[only marks,blue] coordinates {(0,0)};
\end{axis}
\end{tikzpicture}
\answer{Not a subspace.}

\item \begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize
    ,axis equal, axis lines=middle,ymax=4,ymin=-4] 
    \addplot[blue,thick] {4*x};
\end{axis}
\end{tikzpicture}
\answer{Subspace.}
\end{OmitV1}

\setcounter{i}{\value{enumii}}
\end{Parts}\begin{enumerate}
\setcounter{enumii}{\value{i}}

\item \qview{28}{32}{\begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize
    ,axis equal image ,view={\q}{25}   ] 
    \addplot3[blue,samples y=0,thick] ({x*0.8},{x},{-0.6*x});
    \addplot3[only marks,black] coordinates {(0,0,0)};
\end{axis}
\end{tikzpicture}}
\answer{Subspace.}

\begin{OmitV1}
\item \qview{28}{32}{\begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize
    ,axis equal image ,view={\q}{30}   ] 
    \addplot3[blue,samples y=0,thick] ({x-x^3/100},{x},{0.1*x^2});
    \addplot3[only marks,black] coordinates {(0,0,0)};
\end{axis}
\end{tikzpicture}}
\answer{Not a subspace.}

\item \qview{28}{32}{\begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize
    ,axis equal image ,view={\q}{25}   ] 
    \addplot3[blue,samples y=0,thick,only marks,samples=11] ({-x*0.8},{x},{0.6*x});
    \addplot3[only marks,black] coordinates {(0,0,0)};
\end{axis}
\end{tikzpicture}}
\answer{Not a subspace.}
\end{OmitV1}

\item \qview{28}{32}{\begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize
    ,axis equal image  ,view={\q}{30}  ] 
    \addplot3[only marks,black] coordinates {(0,0,0)};
    \addplot3[surf,samples=9,opacity=0.5] {x/3+y/6};
\end{axis}
\end{tikzpicture}}
\answer{Subspace.}

\item \qview{28}{32}{\begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize
    ,axis equal image  ,view={\q}{30}  ] 
    \addplot3[only marks,black] coordinates {(0,0,0)};
    \addplot3[surf,samples=9,opacity=0.5] {4+x/3+y/6};
\end{axis}
\end{tikzpicture}}
\answer{Not a subspace.}

\item \qview{28}{32}{\begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize
    ,axis equal image, width=13em    ] 
    \addplot3[only marks,black] coordinates {(0,0,0)};
    \addplot3[surf,opacity=0.5] {-x^3/100+y/4};
\end{axis}
\end{tikzpicture}}
\answer{Not a subspace.}

\begin{OmitV1}
\item \qview{28}{32}{\begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize
    ,axis equal image  ,view={\q}{30}  ] 
    \addplot3[only marks,black] coordinates {(0,0,0)};
    \addplot3[surf,samples=9,opacity=0.5] {-x/3+y/6};
\end{axis}
\end{tikzpicture}}
\answer{Subspace.}

\item \qview{28}{32}{\begin{tikzpicture} 
\begin{axis}[footnotesize,font=\footnotesize
    ,axis equal image, width=13em    ] 
    \addplot3[only marks,black] coordinates {(0,0,0)};
    \addplot3[surf,opacity=0.5] {-x/4+y^2/20};
\end{axis}
\end{tikzpicture}}
\answer{Not a subspace.}
\end{OmitV1}

\end{enumerate}
\end{exercise}





\begin{exercise}  
Use \cref{def:subspace} to decide whether each of the following is a \idx{subspace}, or not.  Give reasons.
\begin{enumerate}
\item All vectors in the line \(y=2x\)\,.
\answer{Subspace.}

\begin{OmitV1}
\item All vectors in the line \(3.2y=0.8x\)\,.
\answer{Subspace.}

\item All vectors \((x,y)=(t,2+t)\) for all real~\(t\).
\answer{Not a subspace.}
\end{OmitV1}

\item All vectors \((1.3n,-3.4n)\) for all integer~\(n\).
\answer{Not a subspace.}

\item All vectors \((x,y)=(-3.3-0.3t,2.4-1.8t)\) for all real~\(t\).%
\answer{Not a subspace.}

\begin{OmitV1}
\item \(\Span\{(6,-1),(1,2)\}\)
\answer{Subspace.}

\item All vectors \((x,y)=(6-3t,t-2)\) for all real~\(t\).
\answer{Subspace.}
\end{OmitV1}

\item The vectors \((2,1,-3)t+(5,-\frac12,2)s\) for all real \(s,t\).
\answer{Subspace.}

\item The vectors \((0.9,2.4,1)t-(0.2,0.6,0.3)s\) for all real \(s,t\).
\answer{Subspace.}

\begin{OmitV1}
\item All vectors \((x,y)\) such that \(y=x^3\).
\answer{Not a subspace.}

\item All vectors \((x,y,z)\) such that \(x=2t\)\,, \(y=t^2\), and \(z=t/2\) for all~\(t\).
\answer{Not a subspace.}
\end{OmitV1}

\item The vectors \((t,n,2t+3n)\) for all real~\(t\) and integer~\(n\).
\answer{Not a subspace.}

\begin{OmitV1}
\item \(\Span\{(0,-1,1),(-1,0,2)\}\)
\answer{Subspace.}

\item The vectors \((2.7,2.6,-0.8,2.1)s+(0.5,0.1,-1,3.3)t\) for all real~\(s,t\).
\answer{Subspace.}
\end{OmitV1}

\item The vectors \((1.4,2.3,1.5,4)+(1.2,-0.8,-1.2,2)t\) for all real~\(t\).
\answer{Not a subspace.}

\item The vectors \((t^3,2t^3)\) for all real~\(t\) (tricky).
\answer{Subspace.}

\item The vectors \((t^2,3t^2)\) for all real~\(t\) (tricky).
\answer{Not a subspace.}

\end{enumerate}
\end{exercise}





\begin{exercise}  
Let \(\WW_1\)\ and~\(\WW_2\) be any two \idx{subspace}s of~\(\RR^n\) (\cref{def:subspace}).  
\begin{enumerate}
\item Use the definition to prove that the \idx{intersection} of \(\WW_1\)\ and~\(\WW_2\) is also a subspace of~\(\RR^n\).
\item Give an example to prove that the union of \(\WW_1\)\ and~\(\WW_2\) is not necessarily a subspace of~\(\RR^n\).
\end{enumerate}
\end{exercise}





\begin{exercise}  
For each of the following matrices, partially solve \idx{linear equation}s to determine whether the given vector~\(\bv_j\) is in the \idx{column space}, and to determine if the given vector~\(\rv_j\) is in the \idx{row space} of the matrix.
Work small problems by hand, and address larger problems with \script.
Record your working or \script\ commands and output.
% A=round(randn(m,n)*3)+0, b=round(randn(m,1)*3)+0, c=round(randn(n,1)*3)+0, rref([A b]), rref([A' c])
\begin{enumerate}
\item \(\eAii=\begin{bmatrix} 2&1
\\5&4 \end{bmatrix}\),
\(\bv_{\arabic{enumii}}=\begin{bmatrix} 3
\\-2 \end{bmatrix}\),
\(\rv_{\arabic{enumii}}=\begin{bmatrix} 1
\\0 \end{bmatrix}\)
\answer{\(\bv_{\arabic{enumii}}\) is in column space;
\(\rv_{\arabic{enumii}}\)~is in row space.}

\begin{OmitV1}
\item \(\eAii=\begin{bmatrix} -2&1
\\4&-2 \end{bmatrix}\),
\(\bv_{\arabic{enumii}}=\begin{bmatrix} 1
\\-3 \end{bmatrix}\),
\(\rv_{\arabic{enumii}}=\begin{bmatrix} 0\\0 \end{bmatrix}\)
\answer{\(\bv_{\arabic{enumii}}\) is not in column space;
\(\rv_{\arabic{enumii}}\)~is in row space.}

\item \(\eAii=\begin{bmatrix} 1&-1
\\-3&4
\\-3&5 \end{bmatrix}\),
\(\bv_{\arabic{enumii}}=\begin{bmatrix} 5
\\0
\\-1 \end{bmatrix}\),
\(\rv_{\arabic{enumii}}=\begin{bmatrix} 0
\\1 \end{bmatrix}\)
\answer{\(\bv_{\arabic{enumii}}\) is not in column space;
\(\rv_{\arabic{enumii}}\)~is in row space.}
\end{OmitV1}

\item \(\eAii=\begin{bmatrix} -2&-4&-5
\\-6&-2&1 \end{bmatrix}\),
\(\bv_{\arabic{enumii}}=\begin{bmatrix} 3
\\1 \end{bmatrix}\),
\(\rv_{\arabic{enumii}}=\begin{bmatrix} 2
\\-6
\\-11 \end{bmatrix}\)
\answer{\(\bv_{\arabic{enumii}}\) is in column space;
\(\rv_{\arabic{enumii}}\)~is in row space.}

\item \(\eAii=\begin{bmatrix} 3&2&4
\\1&6&0
\\1&-2&2 \end{bmatrix}\),
\(\bv_{\arabic{enumii}}=\begin{bmatrix} 10
\\2
\\4 \end{bmatrix}\),
\(\rv_{\arabic{enumii}}=\begin{bmatrix} 0
\\-1
\\2 \end{bmatrix}\)
\answer{\(\bv_{\arabic{enumii}}\) is in column space;
\(\rv_{\arabic{enumii}}\)~is not in row space.}

\begin{OmitV1}
\item \(\eAii=\begin{bmatrix} 0&-1&-4
\\-2&0&4
\\7&-1&-3
\\1&1&3 \end{bmatrix}\),
\(\bv_{\arabic{enumii}}=\begin{bmatrix} 2
\\3
\\1
\\3 \end{bmatrix}\),
\(\rv_{\arabic{enumii}}=\begin{bmatrix} 1
\\0
\\0 \end{bmatrix}\)
\answer{\(\bv_{\arabic{enumii}}\) is not in column space;
\(\rv_{\arabic{enumii}}\)~is in row space.}

\item \(\eAii=\begin{bmatrix} -2&-1&5&4
\\0&-3&1&-1
\\3&3&4&3 \end{bmatrix}\),
\(\bv_{\arabic{enumii}}=\begin{bmatrix} 1
\\2
\\-4 \end{bmatrix}\),
\(\rv_{\arabic{enumii}}=\begin{bmatrix} 0
\\-3
\\1
\\-1 \end{bmatrix}\)
\answer{\(\bv_{\arabic{enumii}}\) is in column space;
\(\rv_{\arabic{enumii}}\)~is in row space.}
\end{OmitV1}

\item \(\eAii=\begin{bmatrix} -2&1&1&-1
\\2&-2&-1&0
\\-2&1&1&-2
\\2&5&-1&-1 \end{bmatrix}\),
\(\bv_{\arabic{enumii}}=\begin{bmatrix} 2
\\-1
\\3
\\0 \end{bmatrix}\),
\(\rv_{\arabic{enumii}}=\begin{bmatrix} -1
\\-2
\\0
\\-1 \end{bmatrix}\)
\answer{\(\bv_{\arabic{enumii}}\) is in column space;
\(\rv_{\arabic{enumii}}\)~is not in row space.}

\item \(\eAii=\begin{bmatrix} 1.0&0.8&2.1&1.4
\\0.6&-0.1&2.1&1.8
\\0.1&-0.1&2.1&1.2
\\1.7&-1.1&-1.9&2.9 \end{bmatrix}\),
\(\bv_{\arabic{enumii}}=\begin{bmatrix} 4.3
\\1.2
\\0.5
\\0.3 \end{bmatrix}\),
\(\rv_{\arabic{enumii}}=\begin{bmatrix} 0.0
\\1.5
\\-0.5
\\1.0 \end{bmatrix}\)
\answer{\(\bv_{\arabic{enumii}}\) is in column space;
\(\rv_{\arabic{enumii}}\)~is in row space.}

\end{enumerate}
\end{exercise}


\begin{exercise}  
In each of the following, is the given vector in the \idx{nullspace} of the given matrix?
% A=round(randn(m,n)*3)+0, v=null(A);v=v/max(abs(v));[~,d]=rat(v);v=v*max(d(:)), w=round(randn(n,1)*3)+0,A*w
\begin{enumerate}
\item \(\eAii=\begin{bmatrix} -11&-2&5
\\-1&1&1 \end{bmatrix}\),
\(\evii=\begin{bmatrix} -7\\6\\-13 \end{bmatrix}\)
\answer{yes}

\item \(\eAii=\begin{bmatrix} 3&-3&2
\\1&1&-3 \end{bmatrix}\),
\(\evii=\begin{bmatrix} 1
\\1
\\1 \end{bmatrix}\)
\answer{no}

\begin{OmitV1}
\item \(\eAii=\begin{bmatrix} -5&0&-2
\\-6&2&-2
\\0&-5&-1 \end{bmatrix}\),
\(\evii=\begin{bmatrix} -2
\\-1
\\5 \end{bmatrix}\)
\answer{yes}

\item \(\eAii=\begin{bmatrix} -3&-2&0&2
\\5&0&1&-2
\\4&-4&4&2 \end{bmatrix}\),
\(\evii=\begin{bmatrix} 6
\\1
\\-10
\\10 \end{bmatrix}\)
\answer{yes}
\end{OmitV1}

\item \(\eAii=\begin{bmatrix} -3&2&3&1
\\-3&-2&-1&4
\\6&1&-1&-1 \end{bmatrix}\),
\(\evii=\begin{bmatrix} 2
\\-4
\\1
\\-2 \end{bmatrix}\)
\answer{no}

\item \(\eAii=\begin{bmatrix} -4&-2&2&-2
\\2&-1&-2&1
\\0&2&1&0
\\0&0&-8&-2 \end{bmatrix}\),
\(\evii=\begin{bmatrix} 11
\\-2
\\4
\\-16 \end{bmatrix}\)
\answer{yes}

\end{enumerate}
\end{exercise}




\begin{exercise}  
Given the \svd{}s of \cref{ex:hsledvs,ex:csledvs}, write down an \idx{orthonormal basis} for the span of the following sets of vectors.
\begin{enumerate}
\item \((-\frac{9}{5},-4)\),\quad \((\frac{12}{5},-3)\)
\answer{\iv, \jv}

\begin{OmitV1}
\item \((-0.96,-0.72)\),\quad \((1.28,0.96)\)
\answer{\((\frac{4}{5},\frac{3}{5})\)}

\item \((7,-22,-4)/39\),\quad \((-34,-38,-53)/78\)
\answer{\((-1,-2,-2)/3\), \((2,-2,1)/3\)}

\item \((4,4,2)/33\),\quad \((4,4,2)/11\),\quad \((6,6,3)/11\)
\answer{\((2,2,1)/3\)}
\end{OmitV1}

\item \((-\frac{2}{5},\frac{11}{9},\frac{31}{90},\frac{4}{9})\),\quad
\((-\frac{2}{5},\frac{11}{9},\frac{31}{90},\frac{4}{9})\),\quad
\((-\frac{26}{45},-\frac{1}{3},\frac{17}{90},-\frac{2}{9})\), \\
\((\frac{26}{45},\frac{1}{3},-\frac{17}{90},\frac{2}{9})\)
\answer{\((2,-8,-2,-3)/9\), \((8,2,-1,2)/9\)}

\end{enumerate}
\end{exercise}





\begin{exercise} \label{ex:ospanrcn} 
Given any \(m\times n\) matrix~\(A\).
\begin{enumerate}
\item Explain how \cref{pro:ospan} uses an \svd\ to find an \idx{orthonormal basis} for the \idx{column space} of~\(A\).
\item How does the same \svd\ give the orthonormal basis \(\{\hlist\vv r\}\) for the \idx{row space} of~\(A\)?  Justify your answer.
\item Why does the same \svd\ also give the orthonormal basis \(\{\vv_{r+1},\ldots,\vv_n\}\) for the \idx{nullspace} of~\(A\)?  Justify.
\end{enumerate}
\end{exercise}




\begin{exercise} \label{ex:obcrn} 
For each of the following matrices, compute an \svd\ with \script, and then use the properties of \cref{ex:ospanrcn} to write down an \idx{orthonormal basis} for the \idx{column space}, the \idx{row space}, and the \idx{nullspace} of the matrix.
(The bases, especially for the nullspace, may differ in detail depending upon your version of \script.)
% These are used in the next exercise also.
% u=round(randn(m,m)*2); v=round(randn(n,n)*2); r=ceil(rand*min(m,n)), A=u*diag(round(randn(r,1)*2),m,n)*v', [U,S,V]=svd(A), col=U(:,1:r)', row=V(:,1:r)', nuls=V(:,r+1:end)'
\begin{Parts}
\raggedright
\item \(\begin{bmatrix} 19&-36&-18
\\-3&12&6
\\-17&48&24 \end{bmatrix}\)
\setbox\ajrqrbox\hbox{\qrcode{% spaces
A=[19  -36  -18
   -3   12    6
  -17   48   24]
[U,S,V]=svd(A)
}}%
\marginajrbox%
\answer{\twodp\
column space \(\{(-0.61, 0.19, 0.77)\), \((-0.77, -0.36, -0.52)\}\);
row space \(\{(-0.35, 0.84, 0.42)\), \((-0.94, -0.31, -0.15)\}\);
nullspace \(\{(0, 0.45, -0.89)\}\).}


\begin{OmitV1}
\item \(\begin{bmatrix} -12&0&-4
\\-30&-6&4
\\34&22&8
\\-50&-10&12 \end{bmatrix}\)
\setbox\ajrqrbox\hbox{\qrcode{% spaces
A=[-12 0 -4
 -30 -6 4
 34 22 8
 -50 -10 12]
[U,S,V]=svd(A)
}}%
\marginajrbox%
\answer{\twodp\
column space \(\{(-0.15, -0.43, 0.53, -0.72)\), \((-0.07, 0.18, 0.83, 0.52)\), \((-0.94, -0.21, -0.16, 0.21)\}\);
row space \(\{(0.95, 0.30, -0.08)\), \((-0.14, 0.64, 0.75)\), \((0.27, -0.71, 0.65)\}\);
nullspace \(\{\}\).}


\item \(\begin{bmatrix} 0&0&0&0
\\4&10&1&-3
\\2&6&0&-2
\\-2&-4&-1&1 \end{bmatrix}\)
\setbox\ajrqrbox\hbox{\qrcode{% spaces
A=[0 0 0 0
 4 10 1 -3
 2 6 0 -2
 -2 -4 -1 1]
[U,S,V]=svd(A)
}}%
\marginajrbox%
\answer{\twodp\
column space \(\{(0.00, -0.81, -0.48, 0.33)\), \((0.00, -0.08, 0.66, 0.74)\}\);
row space \(\{(-0.35, -0.89, -0.08, 0.27)\), \((-0.48, 0.17, -0.80, -0.32)\}\);
nullspace \(\{(-0.78, 0.36, 0.43, 0.28)\), \((-0.19, -0.22, 0.41, -0.86)\}\).}
\end{OmitV1}


\item \(\begin{bmatrix} -13&9&10&-4&-6
\\-7&27&-2&4&-10
\\-4&0&4&4&-4
\\-4&-18&10&-8&5 \end{bmatrix}\)
\setbox\ajrqrbox\hbox{\qrcode{% spaces
A=[-13 9 10 -4 -6
 -7 27 -2 4 -10
 -4 0 4 4 -4
 -4 -18 10 -8 5]
[U,S,V]=svd(A)
}}%
\marginajrbox%
\answer{\twodp\
column space \(\{(0.30, 0.80, 0.07, -0.52)\),  
\((0.78, 0.07, 0.22, 0.58)\),  
\((0.14, 0.13, -0.97, 0.16)\}\);
row space \(\{(-0.20, 0.90, -0.09, 0.17, -0.34)\),  
\((-0.65, -0.08, 0.67, -0.31, -0.16)\),  
\((0.08, 0.31, -0.18, -0.84, 0.41)\}\);
nullspace \(\{(0.73, 0.18, 0.63, -0.10, -0.20)\),  
\((-0.07, 0.25, 0.33, 0.41, 0.81)\}\).}


\item \(\begin{bmatrix} 1&-2&3&9
\\-1&5&0&0
\\0&3&3&9
\\2&-9&1&3
\\1&-7&-2&-6 \end{bmatrix}\)
\setbox\ajrqrbox\hbox{\qrcode{% spaces
A=[1 -2 3 9
 -1 5 0 0
 0 3 3 9
 2 -9 1 3
 1 -7 -2 -6]
[U,S,V]=svd(A)
}}%
\marginajrbox%
\answer{\twodp\
column space \(\{(-0.53, -0.11, -0.64, 0.01, 0.54)\), \((0.40, -0.37, 0.03, 0.76, 0.35)\}\);
row space \(\{(0.01, -0.34, -0.30, -0.89)\), \((0.21, -0.92, 0.11, 0.32)\}\);
nullspace \(\{(-0.06, -0.01, 0.95, -0.31)\), \((0.98, 0.20, 0.04, -0.08)\}\).}


\begin{OmitV1}
\item \(\begin{bmatrix} 9&3&0&-9
\\15&1&24&-15
\\-12&-4&0&12
\\9&3&0&-9
\\-3&-1&0&3
\\11&5&-8&-11 \end{bmatrix}\)
\setbox\ajrqrbox\hbox{\qrcode{% spaces
A=[9 3 0 -9
 15 1 24 -15
 -12 -4 0 12
 9 3 0 -9
 -3 -1 0 3
 11 5 -8 -11]
[U,S,V]=svd(A)
}}%
\marginajrbox%
\answer{\twodp\
column space \(\{(-0.31, -0.74, 0.41, -0.31, 0.10, -0.30)\), 
\((-0.23, 0.63, 0.31, -0.23, 0.08, -0.62)\}\);
row space \(\{(-0.64, -0.15, -0.39, 0.64)\), 
\((-0.25, -0.23, 0.91, 0.25)\}\);
nullspace \(\{(0.66, 0.20, 0.03, 0.72)\), 
\((0.30, -0.94, -0.16, -0.01)\}\).}


\item \(\begin{bmatrix} -8&17&7&-51&20
\\5&-2&-1&15&-2
\\15&-30&-15&75&-30
\\-2&-1&-5&-33&8 \end{bmatrix}\)
\setbox\ajrqrbox\hbox{\qrcode{% spaces
A=[-8 17 7 -51 20
 5 -2 -1 15 -2
 15 -30 -15 75 -30
 -2 -1 -5 -33 8]
[U,S,V]=svd(A)
}}%
\marginajrbox%
\answer{\twodp\
column space \(\{(0.52, -0.14, -0.79, 0.28)\), \((-0.02, 0.18, -0.37, -0.91)\), \((-0.31, -0.94, -0.09, -0.14)\}\);
row space \(\{(-0.16, 0.29, 0.13, -0.87, 0.33)\), \((-0.15, 0.67, 0.58, 0.40, 0.17)\), \((-0.75, -0.12, 0.19, -0.11, -0.61)\}\);
nullspace \(\{(0.62, 0.05, 0.45, -0.25, -0.59)\), \((-0.05, -0.67, 0.63, 0.02, 0.38)\}\).}
\end{OmitV1}


\item \(\begin{bmatrix} -128&6&55&-28&-1
\\20&12&-31&18&-3
\\-12&-30&39&-24&7
\\-1&6&-1&7&-3 \end{bmatrix}\)
\setbox\ajrqrbox\hbox{\qrcode{% spaces
A=[-128 6 55 -28 -1
20 12 -31 18 -3
-12 -30 39 -24 7
-1 6 -1 7 -3]
[U,S,V]=svd(A)
}}%
\marginajrbox%
\answer{\twodp\
column space \(\{(0.94, -0.24, 0.23, -0.01)\), 
\((-0.32, -0.43, 0.83, -0.14)\), 
\((-0.08, -0.50, -0.14, 0.85)\), 
\((0.07, 0.71, 0.48, 0.50)\}\);
row space \(\{(-0.86, -0.03, 0.46, -0.24, 0.01)\), 
\((0.41, -0.62, 0.54, -0.37, 0.15)\), 
\((0.24, 0.44, 0.70, 0.42, -0.30)\), 
\((-0.20, -0.63, -0.02, 0.75, -0.09)\}\);
nullspace \(\{(0.00, 0.18, 0.13, 0.27, 0.94)\}\).}


\end{Parts}
\end{exercise}




\begin{exercise}  
For each of the matrices in \cref{ex:obcrn}, from your computed bases write down the \idx{dimension} of the \idx{column space}, the \idx{row space}, and the \idx{nullspace}.
Comment on how these confirm the \index{rank theorem}Rank \cref{thm:rank}.
\answer{1, 1, 1;
 3, 3, 0;
 2, 2, 2;
 3, 3, 2;
 2, 2, 2;
 2, 2, 2;
 3, 3, 2;
 4, 4, 1.}
\end{exercise}




\begin{exercise}  
What are the possible values for \(\nullity(A)\) in the following cases?
\begin{Parts}
\item \(A\) is a \(2\times 5\) matrix.
\answer{3,4,5}

\item \(A\) is a \(3\times 3\) matrix.
\answer{0,1,2,3}

\item \(A\) is a \(3\times 2\) matrix.
\answer{0,1,2}

\item \(A\) is a \(4\times 6\) matrix.
\answer{2,3,4,5,6}

\item \(A\) is a \(4\times 4\) matrix.
\answer{0,1,2,3,4}

\item \(A\) is a \(6\times 5\) matrix.
\answer{0,1,2,3,4,5}

\end{Parts}
\end{exercise}






\begin{exercise}[\cite{Cowen1997}]  
Alice and Bob are taking a course on linear algebra. 
One of the problems in their homework assignment is to find the \idx{nullspace} of a \(4\times5\) matrix~\(A\). 
In each of the following cases: are their answers consistent with each other?
Give reasons.
%\begin{verbatim}
%Bt=0+round(randn(3,5)*2), At=round(randn(4,3))*Bt+(rand<0.1)*round(randn(4,5)), sva=svd(At), svb=svd(Bt), svab=svd([At;Bt])
%\end{verbatim}
\begin{enumerate} \sloppy
\item Alice's answer is that the nullspace is spanned by 
\((-2, -2, 0, 2, -6)\), \((1, 5, 4, -3, 11)\), \((3, 5, 2, -4, 13)\), and \((0, -2, -2, 1, -4)\). 
Bob's answer is that the nullspace is spanned by 
\((1, 1, 0, -1, 3)\), \((-2, 0, 2, 1, -2)\), and \((-1, 3, 4, 1, 5)\).% 
\answer{no.}

\item Alice's answer is that the nullspace is spanned by 
\((2,-3,1,-2,-5)\), 
\((2,-7,2,-1,-6)\), 
\((1,-2,1,1,0)\), 
\((3,-6,3,3,0)\). 
Bob's answer is that the nullspace is spanned by 
\((1,-2,1,1,0)\), 
\((0,4,-1,-1,1)\), 
\((1,-1,0,-3,-5)\).%
\answer{yes.}

\item Alice's answer is that the nullspace is spanned by 
\((-2,0,-2,4,-5)\), 
\((0,2,-2,2,-2)\), 
\((0,-2,2,-2,2)\), 
\((-4,-12,8,-4,2)\). 
Bob's answer is that the nullspace is spanned by 
\((0,2,-2,2,-2)\), 
\((-2,-4,2,0,-1)\), 
\((1,0,-1,1,-3)\).% 
\answer{no.}

\item Alice's answer is that the nullspace is spanned by 
\((-1,0,0,0,0)\), 
\((5,3,-2,5,1)\), 
\((-5,1,0,-6,-2)\), 
\((4,-2,0,1,8)\). 
Bob's answer is that the nullspace is spanned by 
\((1,-2,0,-3,4)\), 
\((2,-1,1,3,2)\), 
\((3,0,-1,2,3)\).% 
\answer{no.}

\end{enumerate}
\end{exercise}










\begin{exercise}  
Prove that if the columns of a matrix~\(A\) are orthonormal, then the columns must form an \idx{orthonormal basis} for the \idx{column space} of~\(A\).
% Use an svd for an orthogonal matrix.
\end{exercise}




\begin{exercise}  
Let \(A\) be any \(m\times n\) matrix.  
Use an \svd\ to prove that every vector in the \idx{row space} of~\(A\) is orthogonal to every vector in the \idx{nullspace}.
\end{exercise}







\begin{exercise} \label{ex:wgpwpd} 
Bachlin et al.\ [\emph{IEEE Transactions on Information Technology in Biomedicine}, 14(2), 2010] explored the \idx{walking gait} of people with Parkinson's disease.
Among many measurements, they measured the vertical ankle acceleration of the people when they walked.
\cref{fig:wgpwpd} shows ten seconds of just one example: use the so-called \idx{Singular Spectrum Analysis} to find the regular structures in this complex data.
\begin{figure}
\centering
\begin{tikzpicture}

\begin{axis}[%
xmin=0, xmax=10,
ymin=-8, ymax=6,
xlabel={$\text{time (secs)}$},
ylabel={$\text{acceleration (m/s/s)}$},
axis on top]
\addplot [
color=blue,
solid,
mark=*
]
coordinates{
 (0.062,5.34)(0.187,0.85)(0.312,-1.9)(0.437,-1.39)(0.562,-0.99)(0.687,5.64)(0.812,-1.76)(0.937,-5.9)(1.062,4.74)(1.187,1.85)(1.312,-2.09)(1.437,-1.16)(1.562,-1.58)(1.687,5.19)(1.812,-0.27)(1.937,-6.54)(2.062,3.94)(2.187,2.7)(2.312,-2.36)(2.437,-0.94)(2.562,-1.68)(2.687,4.61)(2.812,0.79)(2.937,-6.9)(3.062,3.23)(3.187,3.59)(3.312,-2.65)(3.437,-0.99)(3.562,-1.65)(3.687,4.09)(3.812,1.78)(3.937,-7.11)(4.062,2.26)(4.187,4.27)(4.312,-2.53)(4.437,-0.84)(4.562,-1.84)(4.687,3.34)(4.812,2.62)(4.937,-6.74)(5.062,1.54)(5.187,4.16)(5.312,-2.29)(5.437,-0.5)(5.562,-1.97)(5.687,2.8)(5.812,2.92)(5.937,-6.37)(6.062,1.09)(6.187,4.17)(6.312,-2.05)(6.437,-0.44)(6.562,-2.03)(6.687,2.08)(6.812,3.91)(6.937,-5.84)(7.062,-0.78)(7.187,4.98)(7.312,-1.28)(7.437,-0.94)(7.562,-1.86)(7.687,0.5)(7.812,5.4)(7.937,-4.19)(8.062,-3.88)(8.187,5.45)(8.312,0.44)(8.437,-1.71)(8.562,-1.59)(8.687,-0.9)(8.812,5.86)(8.937,-1.95)(9.062,-5.95)(9.187,4.75)(9.312,1.9)(9.437,-2.06)(9.562,-1.21)(9.687,-1.61)(9.812,5.16) 
};

\end{axis}
\end{tikzpicture}
\caption{Vertical acceleration of the ankle of a person walking normally, a person who has Parkinson's disease.  The data is recorded \(0.125\)\,s apart (here subsampled and smoothed for the purposes of the exercise).}
\label{fig:wgpwpd}
\end{figure}

Following \cref{eg:orthbapp}:
\begin{enumerate}
\item enter the data into \script;
\setbox\ajrqrbox\hbox{\qrcode{% ankle
time=(0.0625:0.125:9.85)'
acc=[5.34; 0.85; -1.90; -1.39; -0.99; 5.64;
-1.76; -5.90; 4.74; 1.85; -2.09; -1.16; -1.58;
5.19; -0.27; -6.54; 3.94; 2.70; -2.36; -0.94;
-1.68; 4.61; 0.79; -6.90; 3.23; 3.59; -2.65;
-0.99; -1.65; 4.09; 1.78; -7.11; 2.26; 4.27;
-2.53; -0.84; -1.84; 3.34; 2.62; -6.74; 1.54;
4.16; -2.29; -0.50; -1.97; 2.80; 2.92; -6.37;
1.09; 4.17; -2.05; -0.44; -2.03; 2.08; 3.91;
-5.84; -0.78; 4.98; -1.28; -0.94; -1.86; 0.50;
5.40; -4.19; -3.88; 5.45; 0.44; -1.71; -1.59;
-0.90; 5.86; -1.95; -5.95; 4.75; 1.90; -2.06;
-1.21; -1.61; 5.16]
}}%
\marginajrbox%
\begin{verbatim}
time=(0.0625:0.125:9.85)'
acc=[5.34; 0.85; -1.90; -1.39; -0.99; 5.64;
-1.76; -5.90; 4.74; 1.85; -2.09; -1.16; -1.58;
5.19; -0.27; -6.54; 3.94; 2.70; -2.36; -0.94;
-1.68; 4.61; 0.79; -6.90; 3.23; 3.59; -2.65;
-0.99; -1.65; 4.09; 1.78; -7.11; 2.26; 4.27;
-2.53; -0.84; -1.84; 3.34; 2.62; -6.74; 1.54;
4.16; -2.29; -0.50; -1.97; 2.80; 2.92; -6.37;
1.09; 4.17; -2.05; -0.44; -2.03; 2.08; 3.91;
-5.84; -0.78; 4.98; -1.28; -0.94; -1.86; 0.50;
5.40; -4.19; -3.88; 5.45; 0.44; -1.71; -1.59;
-0.90; 5.86; -1.95; -5.95; 4.75; 1.90; -2.06;
-1.21; -1.61; 5.16]
\end{verbatim}
\item use \index{hankel()@\texttt{hankel()}}\verb|hankel()|  to form a matrix whose 66~columns are 66 `windows' of accelerations, each of length fourteen data points (of length \(1.75\)\,s);

\item compute an \svd\ of the matrix, and explain why the windows of measured accelerations are close to lying in a four-dimensional subspace;

\item plot \idx{orthonormal basis} vectors for the four-dimensional subspace of the windowed accelerations.
\end{enumerate}
\end{exercise}


% exercise to discover a basis for some 'real' data??
% http://archive.ics.uci.edu/ml/datasets.html





\begin{exercise} \label{ex:rankobord} 
Consider \(m\times n\) matrices bordered by zeros in the block form
\begin{equation*}
E=\begin{bmatrix} F&O_{k\times n-\ell}
\\O_{m-k\times \ell}& O_{m-k\times n-\ell} \end{bmatrix}
\end{equation*}
where \(F\) is some \(k\times\ell\) matrix.
Given that matrix~\(F\) has an \svd, find an \svd\ of matrix~\(E\), and hence prove that \(\rank E=\rank F\)\,.
% cute to use symbol F as it misses the bottom of E
\end{exercise}

\begin{exercise}  
For compatibly sized matrices~\(A\) and~\(B\), use their \svd{}s, and the result of the previous \cref{ex:rankobord} (applied to the matrix \(S_A\tr V_AU_BS_B\)), to prove that \(\rank(AB)\leq\rank A\) and also that \(\rank(AB)\leq\rank B\)\,.
\end{exercise}




\begin{exercise}  
In a few sentences, answer\slash discuss each of the following.
\begin{enumerate}
\item In \cref{def:subspace} what causes a subspace to be a line, plane, \ldots, through the origin?

\item What is the key feature of the concept of the span of a set that causes the span to always be a subspace?

\item How does the column space of a matrix relate to its row space?

\item Why is an orthonormal basis important?

\item How does the concept of the dimension occur?

\end{enumerate}
\end{exercise}

\begin{comment}%{ED498555.pdf}
why, what caused X?
how did X occur?
what-if? what-if-not?
how does X compare with Y?
what is the evidence for X?
why is X important?
\end{comment}







